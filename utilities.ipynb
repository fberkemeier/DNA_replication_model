{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545005ec-61b3-4b53-8a49-b23b1a402507",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Import dependencies ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e23ec95-6132-4318-a0ff-910b00239a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import csv\n",
    "import h5py\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import LogFormatterMathtext\n",
    "from mpl_scatter_density import ScatterDensityArtist\n",
    "import pyideogram\n",
    "import pybigtools\n",
    "import scipy.optimize\n",
    "import scipy.io\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau, ttest_ind, mannwhitneyu\n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import curve_fit, fsolve\n",
    "from numpy import genfromtxt\n",
    "from typing import Any\n",
    "from time import monotonic\n",
    "import cProfile\n",
    "from random import random\n",
    "from itertools import accumulate\n",
    "from math import floor\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# General options\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The iteration is not making good progress\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Creating legend with loc=\\\"best\\\" can be slow with large amounts of data.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*All-NaN slice encountered.*\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da929f-b18c-44f4-9a69-07476a0b6b80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### General variables ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6402efde-5206-4a1f-96c2-380778c39811",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = [\"HeLa-S3\",\"BJ1\",\"IMR90\",\"HUVEC\",\"K562\",\"GM12878\",\"HepG2\",\"MCF-7\",\"H1\",\"H9\",\"HCT\"]\n",
    "chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, 135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "\n",
    "list1 = [\"time_data\", \"time_sim\", \"error\", \"fire_rates\", \"forkd\",\"telomeres\",\"rna_seq\",\"gro_seq\",\"DNaseIHS\",\"chip_seq\",\"prom\",\"coding\", \"speed_data\", \"speed_sim\"]\n",
    "list2 = [\"Replication time (min)\", \"Replication time (min)\", \"Error\", \"Firing rate\", \"Fork directionality\", \"Telomeres\", \"RNA-Seq\",\"GRO-Seq\",\"DNaseI HS\",\"ChIP-Seq\",\"Promoter\",\"Coding genes\",\"Replication rate (data)\", \"Replication rate (sim)\"]\n",
    "title_map = {key: value for key, value in zip(list1, list2)}\n",
    "\n",
    "plt.rcParams['text.usetex'] = False # Enable LaTeX font rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132e591-99cc-45aa-9153-674a881cebe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9dda26-324d-462b-8f63-507bbcf0cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theory(nmax, v, fmin, fmax, saveQ=False):\n",
    "\n",
    "    def given_function(f, n, v):\n",
    "        sum_part = 0\n",
    "        for k in range((n-3)//2 + 1):\n",
    "            sum_part += (np.exp(-f*k**2/v) - np.exp(-f*(k+1)**2/v)) / (2*k + 1)\n",
    "        \n",
    "        additional_term = np.exp(-f*((n-1)/2)**2/v) / n\n",
    "        \n",
    "        result = (1/f) * (sum_part + additional_term)\n",
    "        return result\n",
    "    \n",
    "    # Parameters\n",
    "    f_values = np.linspace(fmin, fmax, 400)  # f values from 0.0001 to 0.04\n",
    "    n_values = range(1, nmax + 1)  # n values from 1 to 60\n",
    "    \n",
    "    # Setting up the color map\n",
    "    norm = mcolors.Normalize(vmin=min(n_values), vmax=max(n_values))\n",
    "    cmap = plt.colormaps.get_cmap('autumn')\n",
    "    \n",
    "    # Plotting\n",
    "    scl = 0.5\n",
    "    fig, ax = plt.subplots(figsize=(scl * 14, scl * 10))\n",
    "    for n in n_values:\n",
    "        y_values = [given_function(f, n, v) for f in f_values]\n",
    "        ax.plot(f_values, y_values, color=cmap(norm(n)), label=f'n={n}')\n",
    "    \n",
    "    # Adding the additional function plot\n",
    "    additional_y_values = (1/2) * np.sqrt(np.pi / (f_values * v))\n",
    "    blue_plot, = ax.plot(f_values, additional_y_values, color='blue', label=r'$\\frac{1}{2}\\sqrt{\\frac{\\pi}{fv}}$')\n",
    "    \n",
    "    ax.set_xlabel(r'Firing rate ($f$)')\n",
    "    ax.set_ylabel(r'$E[T_j; n]$')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(10**0.55, 10**2)\n",
    "    ax.set_xlim(0, 0.04)\n",
    "    \n",
    "    # Adding color bar inside the plot\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, orientation='horizontal', pad=0.05, fraction=0.05, ax=ax)\n",
    "    cbar.ax.tick_params(size=0)  # Remove ticks\n",
    "    cbar.outline.set_visible(False)  # Remove the frame\n",
    "    cbar.ax.set_position([0.68, 0.81, 0.18, 0.05])  # Adjust position [left, bottom, width, height]\n",
    "    \n",
    "    # Adding the label to the right of the color bar\n",
    "    cbar.ax.text(1.05, 0.5, r'$n$', transform=cbar.ax.transAxes, va='center')\n",
    "    \n",
    "    # Remove colorbar ticks\n",
    "    cbar.set_ticks([])\n",
    "    \n",
    "    # Adding the legend for the blue plot below the color bar\n",
    "    legend = ax.legend(handles=[blue_plot], loc='upper right', bbox_to_anchor=(1, 0.97), fontsize=15)\n",
    "    legend.get_frame().set_linewidth(0)  # Remove legend frame\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/theoryplot.pdf', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c701f5c-5717-42c9-9bdd-592baa314ab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data generation ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d5951-d594-4242-ae85-56b70485f192",
   "metadata": {},
   "source": [
    "##### Replication timing #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d728ea-1786-4f81-aa27-d9836d512292",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BigWig data ###\n",
    "# From: https://genome.ucsc.edu/cgi-bin/hgFileUi?db=hg19&g=wgEncodeUwRepliSeq\n",
    "\n",
    "def sigmoid(values, k):\n",
    "    values = np.array(values)  \n",
    "    if k > 0:\n",
    "        return 50 * (1 + np.tanh((k / 100) * (values - 50)) / np.tanh(0.5 * k))\n",
    "    elif k == 0:\n",
    "        return values  # Identity function when k=0\n",
    "\n",
    "def datagenBigWig(cell_line, chr, minp, maxp, resolution, alld, dtscale, saveQ, info, sigscale=0):\n",
    "    file_path = f'data/bigwig_files/{cell_line}.bigWig'\n",
    "    bw = pybigtools.open(open(file_path, 'rb'))  # Keep the original file opening method as requested\n",
    "    time_data_all = bw.values(f'chr{chr}')\n",
    "    \n",
    "    if not alld:\n",
    "        time_data_all = bw.values(f'chr{chr}', minp * resolution, maxp * resolution)\n",
    "    \n",
    "    # Sample equally spaced values from `time_data_all` with the given resolution\n",
    "    time_data = np.array(time_data_all[::resolution])\n",
    "    \n",
    "\n",
    "    # Identify invalid positions\n",
    "    invalid_positions = np.where(np.isnan(time_data) | (time_data <= 0))[0]\n",
    "    \n",
    "    # Filter the time_data\n",
    "    time_data = np.nan_to_num(time_data, nan=0.0001)  # Map 'nan' to 0.0001\n",
    "    time_data[time_data <= 0] = 0.0001  # Map values less than or equal to 0 to 0.0001\n",
    "    time_data[time_data > 100] = 100  # Cap values greater than 100 to 100\n",
    "    time_data = np.array([100 - i for i in time_data]) # Data is given in inversed scale\n",
    "    # Optional: Apply sigmoid transformation (0 for no transform)\n",
    "    #time_data = sigmoid(time_data, sigscale) # Use k = (0,2,5,10,50)\n",
    "    # Scaling\n",
    "    time_data = dtscale * time_data\n",
    "    interval_min = 30 # The start of the S-phase is often detected within a range of 0 to 30 minutes into the S-phase.\n",
    "    interval_max = max(time_data)\n",
    "    time_data = (time_data - np.min(time_data) )/ (np.max(time_data) - np.min(time_data)) * (interval_max - interval_min) + interval_min\n",
    "    time_data[invalid_positions] = max(time_data)\n",
    "\n",
    "    if saveQ:\n",
    "        np.savetxt(f\"data/whole-genome_timing_data/time_data_{info}.txt\", time_data, fmt='%.30f')\n",
    "        np.savetxt(f\"data/whole-genome_missing_data/missing_data_{info}.txt\", invalid_positions, fmt='%d')\n",
    "\n",
    "    return time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6206e1a-decb-454f-a3b7-faeffd4e7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "### High-resolution data ###\n",
    "# From: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137764\n",
    "\n",
    "def logistic(x, L, k, x0):\n",
    "    \"\"\"Logistic function used for curve fitting.\"\"\"\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "def calculate_medians(rtil2):\n",
    "    \"\"\"Calculates the median time points for each list of observations.\"\"\"\n",
    "    medians = []\n",
    "\n",
    "    for data in rtil2:\n",
    "        if np.sum(data) == 0:\n",
    "            medians.append(np.nan)  # Handle the case of all zeros or no data\n",
    "            continue\n",
    "\n",
    "        # Accumulate the data points\n",
    "        accumulated_data = np.cumsum(data)\n",
    "\n",
    "        # Normalize the accumulated data to have a final value of 1\n",
    "        normalized_data = accumulated_data / accumulated_data[-1]\n",
    "\n",
    "        # Time points evenly distributed over 10 hours\n",
    "        time_points = np.linspace(0, 10, len(data))\n",
    "\n",
    "        # Fit the logistic function to the normalized accumulated data\n",
    "        try:\n",
    "            params, _ = curve_fit(logistic, time_points, normalized_data, p0=[1, 1, 5])\n",
    "            L, k, x0 = params\n",
    "            medians.append(x0)  # Append the median time point\n",
    "        except RuntimeError:\n",
    "            medians.append(np.nan)  # Append NaN if the fit fails\n",
    "\n",
    "    return medians\n",
    "\n",
    "def datagenHighRes(cell_line, chr, minp, maxp, resolution, alld, dtscale, saveQ, info):\n",
    "\n",
    "    global time_data\n",
    "    \n",
    "    # Lengths of each chromosome in kilobases\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, 135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "\n",
    "    # Path to the data file\n",
    "    matfile = f'data/high_res_files/GSE137764_{cell_line}_GaussiansGSE137764_mooth_scaled_autosome.mat'\n",
    "    \n",
    "    # Read the data\n",
    "    data = pd.read_csv(matfile, delimiter=\"\\t\", low_memory=False)\n",
    "    \n",
    "    # Extract relevant columns for the chromosome\n",
    "    selected_columns = [col for col in data.columns if (f'chr{str(chr)}' == col or f'chr{str(chr)}.' in col)]\n",
    "    \n",
    "    rtil1 = []\n",
    "    for col in selected_columns:\n",
    "        lcol = np.array(data[col][2:18])\n",
    "        lcol[np.isnan(lcol)] = 0.  # Ensures no NaNs are processed\n",
    "        rtil1.append(lcol)\n",
    "\n",
    "    rtil2 = calculate_medians(rtil1)  # Assume this function calculates some form of median or summarization\n",
    "    \n",
    "    # Calculate repeat factor and ensure the length is exactly the chromosome length\n",
    "    original_length = len(rtil2)\n",
    "    repeat_factor = chr_lengths[chr - 1] // original_length + (chr_lengths[chr - 1] % original_length > 0)\n",
    "    print(repeat_factor)\n",
    "    \n",
    "    # Create the repeated array, then slice to the exact chromosome length\n",
    "    extended_data = np.repeat(rtil2, repeat_factor)[:chr_lengths[chr - 1]]\n",
    "    \n",
    "    # Apply Gaussian smoothing\n",
    "    sigma = 20  # Standard deviation for Gaussian smoothing\n",
    "    time_data = gaussian_filter(extended_data, sigma=sigma)\n",
    "\n",
    "    invalid_positions = np.where(np.isnan(time_data) | (time_data <= 0))[0]\n",
    "    \n",
    "    # Ensure there are no NaN values in the final output\n",
    "    time_data = np.nan_to_num(time_data)\n",
    "    time_data = 60 * time_data\n",
    "    time_data[invalid_positions] = max(time_data)\n",
    "\n",
    "    if saveQ:\n",
    "        np.savetxt(f\"data/whole-genome_timing_data/time_data_{info}.txt\", time_data, fmt='%.30f')\n",
    "        np.savetxt(f\"data/whole-genome_missing_data/missing_data_{info}.txt\", invalid_positions, fmt='%d')\n",
    "    \n",
    "    return time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52a5644-ad0c-4bb9-88fa-fe4f80e9ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple data generation () ###\n",
    "# To be used in fitting\n",
    "def datagenfs(cell_line, chr_number, chrpos_min, chrpos_max, resolution, alld, dtscale, saveQ, info, sigscale=0):\n",
    "    if alld:\n",
    "        time_data = np.loadtxt(f'data/whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}].txt', dtype=float)\n",
    "    else:\n",
    "        time_data = np.loadtxt(f'data/whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "        np.savetxt(f\"data/whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt\", time_data, fmt='%.30f')\n",
    "    return time_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7088d-a8ab-4dc1-ae5a-9a73df6d6dd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### RNA-Seq files #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee79a66-6bc5-4dc3-815f-645b6ecf2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNA-Seq transcription data ###\n",
    "# From: http://hgdownload.cse.ucsc.edu/gbdb/hg19/bbi/wgEncodeRegTxnCaltechRnaSeqHelas3R2x75Il200SigPooled.bw\n",
    "\n",
    "def datagenBigWig_RNA(cell_line, chr, minp, maxp, resolution, alld, saveQ, info):\n",
    "\n",
    "    global rna_seq_data\n",
    "    \n",
    "    file_path = f'data/rna-seq_files/wgEncodeRegTxnCaltechRnaSeqHelas3R2x75Il200SigPooled.bw'\n",
    "    bw = pybigtools.open(open(file_path, 'rb'))  # Keep the original file opening method as requested\n",
    "    rna_seq_data_all = bw.values(f'chr{chr}')\n",
    "\n",
    "    if not alld:\n",
    "        rna_seq_data_all = bw.values(f'chr{chr}', minp * resolution, maxp * resolution)\n",
    "    \n",
    "    # Sample equally spaced values from `rna_seq_data_all` with the given resolution\n",
    "    rna_seq_data = np.array(rna_seq_data_all[::resolution])\n",
    "    \n",
    "\n",
    "    # Identify invalid positions\n",
    "    invalid_positions = np.where(np.isnan(rna_seq_data))[0]\n",
    "    \n",
    "    # Filter\n",
    "    rna_seq_data[invalid_positions] = max(rna_seq_data)\n",
    "\n",
    "    rna_seq_data = rna_seq_data[0:chr_lengths[chr-1]]\n",
    "\n",
    "    if saveQ:\n",
    "        np.savetxt(f\"data/rna-seq_files/rna_seq_{info}.txt\", rna_seq_data, fmt='%.30f')\n",
    "\n",
    "    return rna_seq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab490c85-f1da-4a03-ab60-01946c48a29d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GRO-Seq files #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c22686-3be4-47fa-8c0d-12f852cd7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenBedgraph_GRO(cell_line, chr_number, saveQ=False):\n",
    "    # Define the path to the compressed BEDGraph file\n",
    "    bedgraph_file = 'data/gro-seq_files/GSM2486801_HUVEC_GROseq_normoxia_rep1.bedGraph.gz'  # Replace with other cell lines\n",
    "    output_file = f'data/gro-seq_files/gro_seq_{cell_line}_chr[{chr_number}].txt'\n",
    "    chromosome = f'chr{chr_number}'\n",
    "    \n",
    "    # Read the compressed BEDGraph file into a DataFrame\n",
    "    with gzip.open(bedgraph_file, 'rt') as f:\n",
    "        columns = ['chrom', 'start', 'end', 'value']\n",
    "        bedgraph_df = pd.read_csv(f, sep='\\t', names=columns, comment='#')\n",
    "\n",
    "    # Filter the DataFrame for the given chromosome\n",
    "    filtered_df = bedgraph_df[bedgraph_df['chrom'] == chromosome]\n",
    "\n",
    "    # Determine the range in base pairs\n",
    "    start_range = filtered_df['start'].min()\n",
    "    end_range = filtered_df['end'].max()\n",
    "\n",
    "    # Convert the range to kilobases\n",
    "    start_kb = start_range // 1000\n",
    "    end_kb = end_range // 1000\n",
    "\n",
    "    # Create an array to count the number of observations for each kilobase\n",
    "    range_kb = int(end_kb - start_kb + 1)  # Ensure range_kb is an integer\n",
    "    values_array = np.zeros(range_kb, dtype=int)\n",
    "\n",
    "    # Count the number of observations at each kilobase\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        start_kb_index = (row['start'] // 1000) - start_kb\n",
    "        end_kb_index = (row['end'] // 1000) - start_kb\n",
    "        for kb in range(int(start_kb_index), int(end_kb_index) + 1):  # Ensure the indices are integers\n",
    "            values_array[kb] += 1\n",
    "\n",
    "    # Extend values_array to match the length of the chromosome\n",
    "    chrom_length_kb = chr_lengths[chr_number - 1]\n",
    "    if len(values_array) < chrom_length_kb:\n",
    "        values_array = np.pad(values_array, (0, chrom_length_kb - len(values_array)), 'constant')\n",
    "\n",
    "    # Save the results to a text file if saveQ is True\n",
    "    if saveQ:\n",
    "        np.savetxt(output_file, values_array, fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e60d6d-7ec0-4a15-8c60-a960f79ad4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenBigWig_GRO(cell_line, saveQ=False):\n",
    "    # Path to the bigWig file\n",
    "    bigwig_file = r\"data\\gro-seq_files\\GSM1480325_K562_GROseq_plus.bigWig\"\n",
    "    \n",
    "    # Chromosome lengths provided (in kb)\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, \n",
    "                   135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    \n",
    "    # Chromosome labels\n",
    "    chromosomes = [f\"{i+1}\" for i in range(len(chr_lengths))]\n",
    "    \n",
    "    # Open the bigWig file using pybigtools\n",
    "    bw = pybigtools.open(open(bigwig_file, 'rb'))\n",
    "    \n",
    "    # Function to create 1kb bins for a given chromosome\n",
    "    def create_1kb_bins(chrom, chrom_size):\n",
    "        bins = []\n",
    "        for start in range(0, chrom_size * 1000, 1000):  # Convert size from kb to bp\n",
    "            end = start + 1000\n",
    "            bins.append([chrom, start, end])\n",
    "        return pd.DataFrame(bins, columns=[\"chrom\", \"start\", \"end\"])\n",
    "    \n",
    "    # Process each chromosome\n",
    "    j=1\n",
    "    for chrom, size in zip(chromosomes, chr_lengths):\n",
    "        # Create 1 kb bins for this chromosome\n",
    "        bins_df = create_1kb_bins(f\"chr{chrom}\", size)\n",
    "        \n",
    "        # Initialize an array to store the score for each 1kb bin\n",
    "        bin_scores = np.zeros(len(bins_df))\n",
    "    \n",
    "        # Iterate over each bin and retrieve the average signal value from the bigWig file\n",
    "        for idx, row in bins_df.iterrows():\n",
    "            start, end = row[\"start\"], row[\"end\"]\n",
    "            \n",
    "            # Ensure the range is valid; bigWig files may not include the very last base, so adjust the range\n",
    "            if start >= bw.chroms(f\"chr{chrom}\"):  # Make sure start is within valid bounds\n",
    "                break  # No more data to process\n",
    "    \n",
    "            end = min(end, bw.chroms(f\"chr{chrom}\"))  # Adjust end to not exceed chromosome length\n",
    "            \n",
    "            # Get the signal values for this 1kb region from the bigWig file\n",
    "            try:\n",
    "                signal_values = bw.values(f\"chr{chrom}\", start, end)\n",
    "                # Handle potential NaN values\n",
    "                if np.isnan(signal_values).all():\n",
    "                    bin_scores[idx] = 0\n",
    "                else:\n",
    "                    bin_scores[idx] = np.nanmean(signal_values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing region {start}-{end} on {chrom}: {e}\")\n",
    "                bin_scores[idx] = 0  # Default to 0 if an error occurs\n",
    "    \n",
    "        # Write the result for this chromosome to a text file\n",
    "        output_file = f\"data/gro-seq_files/gro_seq_{cell_line}_chr[{j}].txt\"\n",
    "        j+=1\n",
    "        if saveQ:\n",
    "            np.savetxt(output_file, bin_scores, fmt='%.6f')\n",
    "    \n",
    "    # Close the bigWig file\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4e957-46ec-4940-b7d3-9c2820d9caf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DNase-I HS files #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9f5da0-9d22-407f-84d6-217146957ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenBigWig_DHS(cell_line, saveQ=False):\n",
    "    # Path to the bigWig file\n",
    "    bigwig_file = r\"data\\DNaseIHS_files\\wgEncodeUwDnaseK562RawRep1.bigWig\" # Replace with other cell lines\n",
    "    \n",
    "    # Chromosome lengths provided (in kb)\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, \n",
    "                   135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    \n",
    "    # Chromosome labels\n",
    "    chromosomes = [f\"{i+1}\" for i in range(len(chr_lengths))]\n",
    "    \n",
    "    # Open the bigWig file using pybigtools\n",
    "    bw = pybigtools.open(open(bigwig_file, 'rb'))\n",
    "    \n",
    "    # Function to create 1kb bins for a given chromosome\n",
    "    def create_1kb_bins(chrom, chrom_size):\n",
    "        bins = []\n",
    "        for start in range(0, chrom_size * 1000, 1000):  # Convert size from kb to bp\n",
    "            end = start + 1000\n",
    "            bins.append([chrom, start, end])\n",
    "        return pd.DataFrame(bins, columns=[\"chrom\", \"start\", \"end\"])\n",
    "    \n",
    "    # Process each chromosome\n",
    "    j=1\n",
    "    for chrom, size in zip(chromosomes, chr_lengths):\n",
    "        # Create 1 kb bins for this chromosome\n",
    "        bins_df = create_1kb_bins(f\"chr{chrom}\", size)\n",
    "        \n",
    "        # Initialize an array to store the score for each 1kb bin\n",
    "        bin_scores = np.zeros(len(bins_df))\n",
    "    \n",
    "        # Iterate over each bin and retrieve the average signal value from the bigWig file\n",
    "        for idx, row in bins_df.iterrows():\n",
    "            start, end = row[\"start\"], row[\"end\"]\n",
    "            \n",
    "            # Ensure the range is valid; bigWig files may not include the very last base, so adjust the range\n",
    "            if start >= bw.chroms(f\"chr{chrom}\"):  # Make sure start is within valid bounds\n",
    "                break  # No more data to process\n",
    "    \n",
    "            end = min(end, bw.chroms(f\"chr{chrom}\"))  # Adjust end to not exceed chromosome length\n",
    "            \n",
    "            # Get the signal values for this 1kb region from the bigWig file\n",
    "            try:\n",
    "                signal_values = bw.values(f\"chr{chrom}\", start, end)\n",
    "                # Handle potential NaN values\n",
    "                if np.isnan(signal_values).all():\n",
    "                    bin_scores[idx] = 0\n",
    "                else:\n",
    "                    bin_scores[idx] = np.nanmean(signal_values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing region {start}-{end} on {chrom}: {e}\")\n",
    "                bin_scores[idx] = 0  # Default to 0 if an error occurs\n",
    "    \n",
    "        # Write the result for this chromosome to a text file\n",
    "        output_file = f\"data/DNaseIHS_files/DNaseIHS_{cell_line}_chr[{j}].txt\"\n",
    "        j+=1\n",
    "        if saveQ:\n",
    "            np.savetxt(output_file, bin_scores, fmt='%.6f')\n",
    "    \n",
    "    # Close the bigWig file\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4f6c65-ebb7-4fe8-a10c-91b346fa5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagennarrowPeak_DHS(cell_line, saveQ=False):\n",
    "    # Path to the gzipped narrowPeak file\n",
    "    narrowpeak_file = r\"data\\DNaseIHS_files\\wgEncodeOpenChromDnaseHelas3Pk.narrowPeak.gz\"\n",
    "    \n",
    "    # Chromosome lengths provided (in kb)\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, \n",
    "                   135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    \n",
    "    # Chromosome labels\n",
    "    chromosomes = [f\"chr{i+1}\" for i in range(len(chr_lengths))]\n",
    "    \n",
    "    # Read and parse the narrowPeak.gz file\n",
    "    peak_data = []\n",
    "    with gzip.open(narrowpeak_file, 'rt') as f:  # Open in text mode\n",
    "        for line in f:\n",
    "            fields = line.strip().split()\n",
    "            peak_data.append({\n",
    "                \"chrom\": fields[0],\n",
    "                \"start\": int(fields[1]),\n",
    "                \"end\": int(fields[2]),\n",
    "                \"signalValue\": float(fields[6])\n",
    "            })\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    peak_df = pd.DataFrame(peak_data)\n",
    "    \n",
    "    # Function to create 1kb bins for a given chromosome\n",
    "    def create_1kb_bins(chrom, chrom_size):\n",
    "        bins = []\n",
    "        for start in range(0, chrom_size * 1000, 1000):  # Convert size from kb to bp\n",
    "            end = start + 1000\n",
    "            bins.append([chrom, start, end])\n",
    "        return pd.DataFrame(bins, columns=[\"chrom\", \"start\", \"end\"])\n",
    "    \n",
    "    # Process each chromosome\n",
    "    j=1\n",
    "    for chrom, size in zip(chromosomes, chr_lengths):\n",
    "        # Create 1 kb bins for this chromosome\n",
    "        bins_df = create_1kb_bins(chrom, size)\n",
    "        \n",
    "        # Filter the peak data for the current chromosome\n",
    "        chrom_peak_df = peak_df[peak_df[\"chrom\"] == chrom]\n",
    "    \n",
    "        # Initialize an array to store the score for each 1kb bin\n",
    "        bin_scores = np.zeros(len(bins_df))\n",
    "    \n",
    "        # Iterate over each peak and assign scores to the corresponding bins\n",
    "        for _, peak in chrom_peak_df.iterrows():\n",
    "            peak_start, peak_end, peak_value = peak[\"start\"], peak[\"end\"], peak[\"signalValue\"]\n",
    "            \n",
    "            # Find the bins overlapping with the peak\n",
    "            bin_start_idx = peak_start // 1000\n",
    "            bin_end_idx = peak_end // 1000\n",
    "            \n",
    "            # Assign the peak value to the overlapping bins\n",
    "            for i in range(bin_start_idx, bin_end_idx + 1):\n",
    "                if i < len(bin_scores):\n",
    "                    bin_scores[i] += peak_value  # Summing the values; you can choose another method\n",
    "        \n",
    "        # Write the result for this chromosome to a text file\n",
    "        output_file = f\"data/DNaseIHS_files/DNaseIHS_{cell_line}_chr[{j}].txt\"\n",
    "        j+=1\n",
    "        if saveQ:\n",
    "            np.savetxt(output_file, bin_scores, fmt='%.6f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb3be8-246b-4c79-8f9d-7c8fea8eb5d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### ChIP-seq files #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db95adc9-1bb6-48d0-9d7f-37ed5fb5f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenBigWig_chip(cell_line, saveQ=False):\n",
    "    # Path to the bigWig file\n",
    "    bigwig_file = r\"data\\chip-seq_files\\wgEncodeUwHistoneK562H3k4me3StdRawRep1.bigWig\"\n",
    "    \n",
    "    # Chromosome lengths provided (in kb)\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, \n",
    "                   135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    \n",
    "    # Chromosome labels\n",
    "    chromosomes = [f\"{i+1}\" for i in range(len(chr_lengths))]\n",
    "    \n",
    "    # Open the bigWig file using pybigtools\n",
    "    bw = pybigtools.open(open(bigwig_file, 'rb'))\n",
    "    \n",
    "    # Function to create 1kb bins for a given chromosome\n",
    "    def create_1kb_bins(chrom, chrom_size):\n",
    "        bins = []\n",
    "        for start in range(0, chrom_size * 1000, 1000):  # Convert size from kb to bp\n",
    "            end = start + 1000\n",
    "            bins.append([chrom, start, end])\n",
    "        return pd.DataFrame(bins, columns=[\"chrom\", \"start\", \"end\"])\n",
    "    \n",
    "    # Process each chromosome\n",
    "    j=1\n",
    "    for chrom, size in zip(chromosomes, chr_lengths):\n",
    "        # Create 1 kb bins for this chromosome\n",
    "        bins_df = create_1kb_bins(f\"chr{chrom}\", size)\n",
    "        \n",
    "        # Initialize an array to store the score for each 1kb bin\n",
    "        bin_scores = np.zeros(len(bins_df))\n",
    "    \n",
    "        # Iterate over each bin and retrieve the average signal value from the bigWig file\n",
    "        for idx, row in bins_df.iterrows():\n",
    "            start, end = row[\"start\"], row[\"end\"]\n",
    "            \n",
    "            # Ensure the range is valid; bigWig files may not include the very last base, so adjust the range\n",
    "            if start >= bw.chroms(f\"chr{chrom}\"):  # Make sure start is within valid bounds\n",
    "                break  # No more data to process\n",
    "    \n",
    "            end = min(end, bw.chroms(f\"chr{chrom}\"))  # Adjust end to not exceed chromosome length\n",
    "            \n",
    "            # Get the signal values for this 1kb region from the bigWig file\n",
    "            try:\n",
    "                signal_values = bw.values(f\"chr{chrom}\", start, end)\n",
    "                # Handle potential NaN values\n",
    "                if np.isnan(signal_values).all():\n",
    "                    bin_scores[idx] = 0\n",
    "                else:\n",
    "                    bin_scores[idx] = np.nanmean(signal_values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing region {start}-{end} on {chrom}: {e}\")\n",
    "                bin_scores[idx] = 0  # Default to 0 if an error occurs\n",
    "    \n",
    "        # Write the result for this chromosome to a text file\n",
    "        output_file = f\"data/chip-seq_files/chip_seq_{cell_line}_chr[{j}].txt\"\n",
    "        j+=1\n",
    "        if saveQ:\n",
    "            np.savetxt(output_file, bin_scores, fmt='%.6f')\n",
    "    \n",
    "    # Close the bigWig file\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46fbf3-38b5-46c5-b270-5f57c6069cb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Promoter files #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0e8f0d-42c9-4c3a-9fbb-1f0c04efb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenBigWig_prom(cell_line, saveQ=False):\n",
    "    # Path to the bigWig file\n",
    "    bigwig_file = r\"data\\promoter_files\\GSM733682_hg19_wgEncodeBroadHistoneHelas3H3k4me3StdSig.bigWig\"\n",
    "    \n",
    "    # Chromosome lengths provided (in kb)\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, \n",
    "                   135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    \n",
    "    # Chromosome labels\n",
    "    chromosomes = [f\"{i+1}\" for i in range(len(chr_lengths))]\n",
    "    \n",
    "    # Open the bigWig file using pybigtools\n",
    "    bw = pybigtools.open(open(bigwig_file, 'rb'))\n",
    "    \n",
    "    # Function to create 1kb bins for a given chromosome\n",
    "    def create_1kb_bins(chrom, chrom_size):\n",
    "        bins = []\n",
    "        for start in range(0, chrom_size * 1000, 1000):  # Convert size from kb to bp\n",
    "            end = start + 1000\n",
    "            bins.append([chrom, start, end])\n",
    "        return pd.DataFrame(bins, columns=[\"chrom\", \"start\", \"end\"])\n",
    "    \n",
    "    # Process each chromosome\n",
    "    j=1\n",
    "    for chrom, size in zip(chromosomes, chr_lengths):\n",
    "        # Create 1 kb bins for this chromosome\n",
    "        bins_df = create_1kb_bins(f\"chr{chrom}\", size)\n",
    "        \n",
    "        # Initialize an array to store the score for each 1kb bin\n",
    "        bin_scores = np.zeros(len(bins_df))\n",
    "    \n",
    "        # Iterate over each bin and retrieve the average signal value from the bigWig file\n",
    "        for idx, row in bins_df.iterrows():\n",
    "            start, end = row[\"start\"], row[\"end\"]\n",
    "            \n",
    "            # Ensure the range is valid; bigWig files may not include the very last base, so adjust the range\n",
    "            if start >= bw.chroms(f\"chr{chrom}\"):  # Make sure start is within valid bounds\n",
    "                break  # No more data to process\n",
    "    \n",
    "            end = min(end, bw.chroms(f\"chr{chrom}\"))  # Adjust end to not exceed chromosome length\n",
    "            \n",
    "            # Get the signal values for this 1kb region from the bigWig file\n",
    "            try:\n",
    "                signal_values = bw.values(f\"chr{chrom}\", start, end)\n",
    "                # Handle potential NaN values\n",
    "                if np.isnan(signal_values).all():\n",
    "                    bin_scores[idx] = 0\n",
    "                else:\n",
    "                    bin_scores[idx] = np.nanmean(signal_values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing region {start}-{end} on {chrom}: {e}\")\n",
    "                bin_scores[idx] = 0  # Default to 0 if an error occurs\n",
    "    \n",
    "        # Write the result for this chromosome to a text file\n",
    "        output_file = f\"data/promoter_files/prom_{cell_line}_chr[{j}].txt\"\n",
    "        j+=1\n",
    "        if saveQ:\n",
    "            np.savetxt(output_file, bin_scores, fmt='%.6f')\n",
    "    \n",
    "    # Close the bigWig file\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c8ac8d-ecbc-4121-adab-ce41a3d0ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenBigWig_prom_smooth(cell_line, saveQ=False):\n",
    "    # Path to the bigWig file\n",
    "    bigwig_file = r\"data/promoter_files/wgEncodeBroadHistoneHuvecH3k4me3StdSig.bigWig\"\n",
    "    \n",
    "    # Chromosome lengths provided (in kb)\n",
    "    chr_lengths = [249251]#, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, \n",
    "                   #135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    \n",
    "    # Chromosome labels\n",
    "    chromosomes = [f\"{i+1}\" for i in range(len(chr_lengths))]\n",
    "    \n",
    "    # Open the bigWig file using pybigtools\n",
    "    bw = pybigtools.open(open(bigwig_file, 'rb'))\n",
    "\n",
    "    # Define Gaussian smoothing parameters\n",
    "    sigma = 50  # Adjust the sigma for the Gaussian smoothing\n",
    "    \n",
    "    # Process each chromosome\n",
    "    j = 1\n",
    "    for chrom, size in zip(chromosomes, chr_lengths):\n",
    "        chrom = f\"chr{chrom}\"\n",
    "        \n",
    "        # Retrieve all values for the entire chromosome\n",
    "        chrom_length = bw.chroms(chrom)\n",
    "        \n",
    "        # Get the signal values for the entire chromosome\n",
    "        signal_values = bw.values(chrom, 0, chrom_length)\n",
    "\n",
    "        # Convert to numpy array (list of values needs to be converted to numpy array)\n",
    "        signal_values = np.array(signal_values)\n",
    "        \n",
    "        # Apply Gaussian smoothing to the entire chromosome\n",
    "        smoothed_values = gaussian_filter1d(signal_values, sigma=sigma, mode='constant', cval=np.nan)\n",
    "        \n",
    "        # Create 1kb bins for this chromosome, and handle the remainder at the end\n",
    "        num_bins = chrom_length // 1000\n",
    "        remainder = chrom_length % 1000\n",
    "        \n",
    "        # Initialize an array to store the score for each 1kb bin plus the remainder\n",
    "        bin_scores = np.zeros(num_bins + (1 if remainder > 0 else 0))\n",
    "        \n",
    "        # Sample the smoothed values at 1 kb intervals\n",
    "        for i in range(num_bins):\n",
    "            start = i * 1000\n",
    "            end = start + 1000\n",
    "            bin_scores[i] = np.nanmean(smoothed_values[start:end])\n",
    "        \n",
    "        # Handle the remainder, if there is one\n",
    "        if remainder > 0:\n",
    "            bin_scores[-1] = np.nanmean(smoothed_values[num_bins * 1000:])\n",
    "        \n",
    "        # Write the result for this chromosome to a text file\n",
    "        output_file = f\"data/promoter_files/prom_{cell_line}_chr[{j}]_smooth.txt\"\n",
    "        j += 1\n",
    "        \n",
    "        if saveQ:\n",
    "            np.savetxt(output_file, bin_scores, fmt='%.6f')\n",
    "    \n",
    "    # Close the bigWig file\n",
    "    bw.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8be19-7918-4187-805d-710abad2db6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Fork speed files #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f82b778-5698-4a36-937e-ca126ccd36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen_speed(cell_line, chr_number, timedata, timesim):\n",
    "    # Calculate the discrete derivative (slope)\n",
    "    speed_data = np.abs(np.diff(timedata, prepend=timedata[0]))\n",
    "    speed_sim = np.abs(np.diff(timesim, prepend=timesim[0]))\n",
    "    \n",
    "    # Avoid division by zero by replacing zeros in speed_data with a small value\n",
    "    speed_data[speed_data == 0] = np.inf  # Set to infinity to represent no movement\n",
    "    speed_sim[speed_sim == 0] = np.inf  # Set to infinity to represent no movement\n",
    "    \n",
    "    # Calculate the inverse of the slope\n",
    "    inverse_speed_data = 1 / speed_data\n",
    "    inverse_speed_sim = 1 / speed_sim\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file_data = f'data/fork_speed/speed_data_{cell_line}_chr[{chr_number}].txt'\n",
    "    output_file_sim = f'data/fork_speed/speed_sim_{cell_line}_chr[{chr_number}].txt'\n",
    "    \n",
    "    # Save the inverse_speed_data to a text file, each value on a new line\n",
    "    np.savetxt(output_file_data, inverse_speed_data, fmt='%f')\n",
    "    np.savetxt(output_file_sim, inverse_speed_sim, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a065a-64fe-43c4-a3ff-4fb074f633d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fitting ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c3ba13-3447-47a7-a1ff-36f7428263d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitfunction(list, v0, st0, fit_step, maxiter, err_threshold, saveQ, info):\n",
    "    \n",
    "    timel = list\n",
    "    \n",
    "    v = v0\n",
    "    st = st0\n",
    "    exp_v = np.exp(-1/v)\n",
    "    x00 = np.array([(math.pi/(4*v))*i**(-2) for i in timel])\n",
    "    lm = 1000 # Remove end regions for error calculation\n",
    "    \n",
    "    # VECTORIZED APPROACH\n",
    "    \n",
    "    def mse(y_true, y_pred):\n",
    "        mse_value = sum((yt - yp) ** 2 for yt, yp in zip(y_true, y_pred)) / len(y_true)\n",
    "        return mse_value\n",
    "    \n",
    "    def fast_roll_add(dst, src, shift):\n",
    "        dst[shift:] += src[:-shift]\n",
    "        dst[:shift] += src[-shift:]\n",
    "    \n",
    "    # Expected replication time computation (replaces bcs)\n",
    "    def fp(x, L, v):\n",
    "        n = len(x)\n",
    "        y = np.zeros(n)\n",
    "    \n",
    "        last_exp_2_raw = np.zeros(n)\n",
    "        last_exp_2 = np.ones(n)\n",
    "        unitary = x.copy()\n",
    "        for k in range(L+1):\n",
    "            if k != 0:\n",
    "                fast_roll_add(unitary, x, k)\n",
    "                fast_roll_add(unitary, x, -k)\n",
    "            exp_1_raw = last_exp_2_raw\n",
    "            exp_1 = last_exp_2\n",
    "            exp_2_raw = exp_1_raw + unitary / v\n",
    "            exp_2 = np.exp(-exp_2_raw)\n",
    "    \n",
    "            # Compute the weighted sum for each j and add to the total\n",
    "            y += (exp_1 - exp_2) / unitary\n",
    "            \n",
    "            last_exp_2_raw = exp_2_raw\n",
    "            last_exp_2 = exp_2\n",
    "        return y\n",
    "\n",
    "    # Fitting iteration\n",
    "    def fitf(time, lst, x0, j, fit_step):\n",
    "        return x0[j] * (lst[j] / time[j])**(fit_step)\n",
    "\n",
    "    # Alternative fitting\n",
    "    def fitf0(time, lst, x0, j, fit_step):\n",
    "        return x0[j]**(np.log(time[j]) / np.log(lst[j]))\n",
    "\n",
    "    # Fitting control\n",
    "    def cfit(time, lst, x0, fit_step):\n",
    "        result = np.empty_like(x0)\n",
    "        for j in range(len(x0)):\n",
    "            fit_result = fitf(time, lst, x0, j, fit_step)\n",
    "            if fit_result < 10**(-err_threshold):\n",
    "                result[j] = 10**(-err_threshold)\n",
    "            #elif abs(time[j] - lst[j]) < .5:\n",
    "            #    result[j] = x0[j]\n",
    "            else:\n",
    "                result[j] = fit_result\n",
    "        return result\n",
    "    \n",
    "    xs = x00\n",
    "    ys = fp(xs, len(xs)//st, v)\n",
    "    new_err0 = mse(timel[lm:-lm], ys[lm:-lm])\n",
    "    err = 10**10\n",
    "    \n",
    "    for j in range(maxiter):\n",
    "        xs0 = xs\n",
    "        ys0 = ys\n",
    "        xs = cfit(timel, ys, xs, fit_step)\n",
    "        ys = fp(xs, len(xs)//st, v)\n",
    "        \n",
    "        new_err = mse(timel[lm:-lm], ys[lm:-lm])\n",
    "        print(str(j+1) + '/' + str(maxiter) + ' err: ' + str('{:.30f}'.format(new_err)), end=\"\\r\")\n",
    "        \n",
    "        err = new_err  # Update the error with the new calculated error\n",
    "\n",
    "    fire_rates = ['{:.30f}'.format(i) for i in xs]\n",
    "    time_sim = ys\n",
    "    \n",
    "    if saveQ:\n",
    "        with open(r'data/whole-genome_firing_rates/fire_rates_'+info+'.txt', 'w') as f:\n",
    "            for rate in fire_rates:\n",
    "                f.write(rate + '\\n')\n",
    "        np.savetxt(r'data/whole-genome_timing_simulation/time_sim_'+info+'.txt', time_sim, fmt='%.30f')\n",
    "    \n",
    "    return [fire_rates, time_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d2a69f-9cde-4271-b799-c6bae8111e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitfunction(list, v0, st0, fit_step, maxiter, err_threshold, saveQ, info, cell_line='', chr_number=''):\n",
    "    \n",
    "    timel = list\n",
    "    \n",
    "    v = v0\n",
    "    st = st0\n",
    "    exp_v = np.exp(-1/v)\n",
    "    x00 = np.array([(math.pi/(4*v))*i**(-2) for i in timel])\n",
    "    lm = 1000 # Remove end regions for error calculation\n",
    "    \n",
    "    # VECTORIZED APPROACH\n",
    "    \n",
    "    def mse(y_true, y_pred):\n",
    "        mse_value = sum((yt - yp) ** 2 for yt, yp in zip(y_true, y_pred)) / len(y_true)\n",
    "        return mse_value\n",
    "    \n",
    "    def fast_roll_add(dst, src, shift):\n",
    "        dst[shift:] += src[:-shift]\n",
    "        dst[:shift] += src[-shift:]\n",
    "    \n",
    "    # Expected replication time computation (replaces bcs)\n",
    "    def fp(x, L, v):\n",
    "        n = len(x)\n",
    "        y = np.zeros(n)\n",
    "    \n",
    "        last_exp_2_raw = np.zeros(n)\n",
    "        last_exp_2 = np.ones(n)\n",
    "        unitary = x.copy()\n",
    "        for k in range(L+1):\n",
    "            if k != 0:\n",
    "                fast_roll_add(unitary, x, k)\n",
    "                fast_roll_add(unitary, x, -k)\n",
    "            exp_1_raw = last_exp_2_raw\n",
    "            exp_1 = last_exp_2\n",
    "            exp_2_raw = exp_1_raw + unitary / v\n",
    "            exp_2 = np.exp(-exp_2_raw)\n",
    "    \n",
    "            # Compute the weighted sum for each j and add to the total\n",
    "            y += (exp_1 - exp_2) / unitary\n",
    "            \n",
    "            last_exp_2_raw = exp_2_raw\n",
    "            last_exp_2 = exp_2\n",
    "        return y\n",
    "\n",
    "    # Fitting iteration\n",
    "    def fitf(time, lst, x0, j, fit_step):\n",
    "        return x0[j] * (lst[j] / time[j])**(fit_step)\n",
    "\n",
    "    # Alternative fitting\n",
    "    def fitf0(time, lst, x0, j, fit_step):\n",
    "        return x0[j]**(np.log(time[j]) / np.log(lst[j]))\n",
    "\n",
    "    # Fitting control\n",
    "    def cfit(time, lst, x0, fit_step):\n",
    "        result = np.empty_like(x0)\n",
    "        for j in range(len(x0)):\n",
    "            fit_result = fitf(time, lst, x0, j, fit_step)\n",
    "            if fit_result < 10**(-err_threshold):\n",
    "                result[j] = 10**(-err_threshold)\n",
    "            else:\n",
    "                result[j] = fit_result\n",
    "        return result\n",
    "    \n",
    "    xs = x00\n",
    "    ys = fp(xs, len(xs)//st, v)\n",
    "    new_err0 = mse(timel[lm:-lm], ys[lm:-lm])\n",
    "    err = 10**10\n",
    "\n",
    "    # Open the file to store the error values\n",
    "    with open(f'data/whole-genome_mse/mse_{cell_line}_chr[{chr_number}].txt', 'a') as mse_file:\n",
    "        # Write the initial error to the file before the loop\n",
    "        mse_file.write(f'{new_err0:.30f}\\n')\n",
    "\n",
    "        for j in range(maxiter):\n",
    "            xs0 = xs\n",
    "            ys0 = ys\n",
    "            xs = cfit(timel, ys, xs, fit_step)\n",
    "            ys = fp(xs, len(xs)//st, v)\n",
    "            \n",
    "            new_err = mse(timel[lm:-lm], ys[lm:-lm])\n",
    "            print(str(j+1) + '/' + str(maxiter) + ' err: ' + str('{:.30f}'.format(new_err)), end=\"\\r\")\n",
    "            \n",
    "            # Write the new error to the file\n",
    "            mse_file.write(f'{new_err:.30f}\\n')\n",
    "            \n",
    "            err = new_err  # Update the error with the new calculated error\n",
    "\n",
    "    fire_rates = ['{:.30f}'.format(i) for i in xs]\n",
    "    time_sim = ys\n",
    "    \n",
    "    if saveQ:\n",
    "        with open(r'data/whole-genome_firing_rates/fire_rates_'+info+'.txt', 'w') as f:\n",
    "            for rate in fire_rates:\n",
    "                f.write(rate + '\\n')\n",
    "        np.savetxt(r'data/whole-genome_timing_simulation/time_sim_'+info+'.txt', time_sim, fmt='%.30f')\n",
    "    \n",
    "    return [fire_rates, time_sim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98edf98-ea6d-4f6d-aaf4-f69b89c2d44a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Error generation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2994092-64b9-4128-812d-722816580b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_squared_error(time_data, time_simulation):\n",
    "    return (time_data - time_simulation) ** 2\n",
    "\n",
    "def process_files_and_compute_squared_error(cell_lines, chr_numbers, base_path):\n",
    "    for cell_line in cell_lines:\n",
    "        for chr_number in chr_numbers:\n",
    "            # Define file paths\n",
    "            time_data_file = os.path.join(base_path, f'whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}].txt')\n",
    "            time_simulation_file = os.path.join(base_path, f'whole-genome_timing_simulation/time_sim_{cell_line}_chr[{chr_number}].txt')\n",
    "            error_file = os.path.join(base_path, f'whole-genome_error/error_{cell_line}_chr[{chr_number}].txt')\n",
    "\n",
    "            # Load data\n",
    "            time_data = np.loadtxt(time_data_file, dtype=float)\n",
    "            time_simulation = np.loadtxt(time_simulation_file, dtype=float)\n",
    "\n",
    "            # Compute squared error\n",
    "            squared_error = compute_squared_error(time_data, time_simulation)\n",
    "            \n",
    "            # Save squared error to file\n",
    "            np.savetxt(error_file, squared_error, fmt='%.30f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb7139-d379-4755-bfbf-e43b74e84a3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### bedgraph file generation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb547147-b0fd-4a61-b9fa-0b5b881d837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of chromosome sizes for hg18\n",
    "def chr_size_fun(genome_build):\n",
    "    if genome_build == 'hg18':\n",
    "        return {\n",
    "            '1': 247249719, '2': 242951149, '3': 199501827, '4': 191273063, '5': 180857866, \n",
    "            '6': 170899992, '7': 158821424, '8': 146274826, '9': 140273252, '10': 135374737, \n",
    "            '11': 134452384, '12': 132349534, '13': 114142980, '14': 106368585, '15': 100338915, \n",
    "            '16': 88827254, '17': 78774742, '18': 76117153, '19': 63811651, '20': 62435964, \n",
    "            '21': 46944323, '22': 49691432, 'X': 154913754, 'Y': 57772954\n",
    "        }\n",
    "    elif genome_build == 'hg19':\n",
    "        return {\n",
    "            '1': 249250621, '2': 243199373, '3': 198022430, '4': 191154276, '5': 180915260,\n",
    "            '6': 171115067, '7': 159138663, '8': 146364022, '9': 141213431, '10': 135534747,\n",
    "            '11': 135006516, '12': 133851895, '13': 115169878, '14': 107349540, '15': 102531392,\n",
    "            '16': 90354753, '17': 81195210, '18': 78077248, '19': 59128983, '20': 63025520,\n",
    "            '21': 48129895, '22': 51304566, 'X': 155270560, 'Y': 59373566\n",
    "        }\n",
    "    elif genome_build == 'hg38':\n",
    "        return {\n",
    "            '1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259,\n",
    "            '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422,\n",
    "            '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189,\n",
    "            '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167,\n",
    "            '21': 46709983, '22': 50818468, 'X': 156040895, 'Y': 57227415\n",
    "        }\n",
    "\n",
    "def txt_to_bedgraph(cell_line, data_type='error', genome_build='hg19'):\n",
    "    # Define the output file name\n",
    "    if data_type=='error':\n",
    "        output_file = f'data/whole-genome_error/bedgraph_files/error_{cell_line}.bedgraph'\n",
    "    elif data_type=='fire_rates':\n",
    "        output_file = f'data/whole-genome_firing_rates/bedgraph_files/fire_rates_{cell_line}.bedgraph'\n",
    "    \n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as bedgraph:\n",
    "        # Write the header line\n",
    "        bedgraph.write('track type=bedGraph\\n')\n",
    "        \n",
    "        # Iterate through all the txt files for the specified cell line\n",
    "        for chr_number in list(map(str, range(1, 23))) + ['X', 'Y']:\n",
    "            if data_type=='error':\n",
    "                input_file = f'data/whole-genome_error/error_{cell_line}_chr[{chr_number}].txt'\n",
    "            elif data_type=='fire_rates':\n",
    "                input_file = f'data/whole-genome_firing_rates/fire_rates_{cell_line}_chr[{chr_number}].txt'\n",
    "            chr_size = chr_size_fun(genome_build)[chr_number]\n",
    "            \n",
    "            # Check if the input file exists\n",
    "            if os.path.isfile(input_file):\n",
    "                with open(input_file, 'r') as infile:\n",
    "                    # Read through each line and write the corresponding bedgraph entry\n",
    "                    for position, value in enumerate(infile):\n",
    "                        start = position * 1000\n",
    "                        end = min(start + 1000, chr_size)\n",
    "                        if start >= chr_size:\n",
    "                            break\n",
    "                        value = value.strip()\n",
    "                        bedgraph.write(f'chr{chr_number}\\t{start}\\t{end}\\t{value}\\n')\n",
    "            else:\n",
    "                None\n",
    "                \n",
    "    print(f'BEDGRAPH file created: {output_file}', end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254806eb-f568-4a39-85f9-c03dbcba5830",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### BCS file generation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f436032-2f6c-4b23-a315-ab34e7703950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcs_gen(cell_line, chr_number, chrpos_min, chrpos_max, fork_speed, fire_rates, resolution):\n",
    "\n",
    "    file_name = cell_line+'_chr['+str(chr_number)+']_'+str(chrpos_min)+'-'+str(chrpos_max)\n",
    "    \n",
    "    bcfile = 'code/DNAReplication.bc'\n",
    "    new_bcfile = f'code/bcs_scripts/DNAReplication_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.bc'\n",
    "    bcsfile = []\n",
    "    \n",
    "    chrLength = chrpos_max - chrpos_min\n",
    "    orign = int(chrLength * resolution / 1000)\n",
    "    fast = 100000\n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrLength)  # Chromosome positions\n",
    "    \n",
    "    with open(bcfile, 'r') as file:\n",
    "        bcsfile = file.readlines()\n",
    "    bcsfile[bcsfile.index(\"// Chromosome length\\n\")+1] = \"L = \"+str(chrLength)+\";\\n\"\n",
    "    bcsfile[bcsfile.index(\"// Fast rate\\n\")+1] = \"fast = \"+str(fast)+\";\\n\"\n",
    "    bcsfile[bcsfile.index(\"// Fork velocity\\n\")+1] = \"v = \"+str(fork_speed)+\";\\n\"\n",
    "    \n",
    "    oril = list(map(floor, np.linspace(1, chrLength, num=orign)))\n",
    "    \n",
    "    flistn = fire_rates\n",
    "    \n",
    "    # write new origins\n",
    "    oriarr = np.array([\n",
    "        'ORI[' + str(floor(oril[i1])) + ',' + '{:.30f}'.format(flistn[i1]) + ']'\n",
    "        for i1 in range(0, orign)\n",
    "    ])\n",
    "    \n",
    "    # delete all the origins\n",
    "    with open(new_bcfile, 'w') as fp:\n",
    "        for number, line in enumerate(bcsfile):\n",
    "            if number not in range(bcsfile.index(\"// PROCESS INITIATION\\n\")+1, bcsfile.index(\"// END\")-2):\n",
    "                fp.write(line)\n",
    "        \n",
    "    # now change the last line\n",
    "    with open(new_bcfile, 'r') as file:\n",
    "        bcsfile = file.readlines()\n",
    "        bcsfile[bcsfile.index(\"// PROCESS INITIATION\\n\")+1] = str(oriarr).replace('\"','').replace(\"'\",'').replace(\" \",\" || \")[1:-1]+';\\n'\n",
    "    \n",
    "    with open(new_bcfile, 'w') as file:\n",
    "        file.writelines(bcsfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85fb9f-01aa-4173-b4d0-063f3dabca2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### BCS simulation output ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cabe8e-2d2e-46e6-a52d-0711f95f2b6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Replication timing, fork directionality and origins #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87aa4633-909b-4825-867c-6bb36db250f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bcs_output(cell_line, chr_number, chrpos_min, chrpos_max, fork_speed, resolution, scale_factor, sim_number, compute_replication_time, compute_fork_directionality, compute_origin_positions):\n",
    "    # Define the file path\n",
    "    file_path = f'data/bcs_output/bcs_output_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.simulation.bcs'\n",
    "\n",
    "    # Initialize arrays to store replication time and fork directionality\n",
    "    DNA_replicationtime = [0.0 for _ in range(0, chrpos_max - chrpos_min)] if compute_replication_time else None\n",
    "    DNA_forkdirectionality = [0.0 for _ in range(0, chrpos_max - chrpos_min)] if compute_fork_directionality else None\n",
    "    DNA_originpositions = [] if compute_origin_positions else None  # List to store origin positions per simulation\n",
    "    current_origins = []\n",
    "    sim_iteration = 0\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            if sim_iteration == sim_number + 1:\n",
    "                break\n",
    "            if line[0] == '>':\n",
    "                alreadyDone = []\n",
    "                if compute_origin_positions and current_origins:  # If we have collected origins for the current simulation\n",
    "                    DNA_originpositions.append(current_origins)\n",
    "                current_origins = []\n",
    "                print(sim_iteration, end=\"\\r\")\n",
    "                sim_iteration += 1\n",
    "                continue\n",
    "            splitLine = line.split('\\t')\n",
    "            if compute_origin_positions and splitLine[2] == \"ORI\":\n",
    "                origin_pos = int(splitLine[4])\n",
    "                current_origins.append(origin_pos)\n",
    "            if splitLine[2] == \"FL\":\n",
    "                pos = int(splitLine[4]) - 1\n",
    "                time = float(splitLine[0])\n",
    "                if pos not in alreadyDone:\n",
    "                    if compute_replication_time:\n",
    "                        DNA_replicationtime[pos] += time\n",
    "                    if compute_fork_directionality:\n",
    "                        DNA_forkdirectionality[pos] -= 1  # Track left-moving forks\n",
    "                    alreadyDone.append(pos)\n",
    "            if splitLine[2] == \"FR\":\n",
    "                pos = int(splitLine[4]) - 1\n",
    "                time = float(splitLine[0])\n",
    "                if pos not in alreadyDone:\n",
    "                    if compute_replication_time:\n",
    "                        DNA_replicationtime[pos] += time\n",
    "                    if compute_fork_directionality:\n",
    "                        DNA_forkdirectionality[pos] += 1  # Track right-moving forks\n",
    "                    alreadyDone.append(pos)\n",
    "\n",
    "    # Don't forget to add the origins of the last simulation\n",
    "    if compute_origin_positions and current_origins:\n",
    "        DNA_originpositions.append(current_origins)\n",
    "\n",
    "    # Average the results over the number of simulations\n",
    "    if compute_replication_time:\n",
    "        for i in range(len(DNA_replicationtime)):\n",
    "            DNA_replicationtime[i] = float(DNA_replicationtime[i]) / float(sim_number)\n",
    "\n",
    "    if compute_fork_directionality:\n",
    "        for i in range(len(DNA_forkdirectionality)):\n",
    "            DNA_forkdirectionality[i] = float(DNA_forkdirectionality[i]) / float(sim_number)\n",
    "\n",
    "    # Define file paths for saving the results\n",
    "    base_path = 'data'\n",
    "    replication_time_path = os.path.join(base_path, 'whole-genome_timing_bcs', f'time_bcs_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt')\n",
    "    fork_directionality_path = os.path.join(base_path, 'whole-genome_fork_directionality', f'fork_directionality_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt')\n",
    "    origin_positions_path = os.path.join(base_path, 'whole-genome_origins', f'origin_positions_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt')\n",
    "\n",
    "    # Create directories if they do not exist\n",
    "    os.makedirs(os.path.dirname(replication_time_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(fork_directionality_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(origin_positions_path), exist_ok=True)\n",
    "\n",
    "    # Save the results to text files\n",
    "    if compute_replication_time:\n",
    "        np.savetxt(replication_time_path, DNA_replicationtime, fmt='%.6f')\n",
    "\n",
    "    if compute_fork_directionality:\n",
    "        np.savetxt(fork_directionality_path, DNA_forkdirectionality, fmt='%.6f')\n",
    "\n",
    "    if compute_origin_positions:\n",
    "        with open(origin_positions_path, 'w') as f:\n",
    "            for origins in DNA_originpositions:\n",
    "                f.write(' '.join(map(str, origins)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96348c62-df12-4924-980d-3ae248b3c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_intervals(cell_lines, chr_numbers, fork_speed=1.4, resolution=1000, scale_factor=6, sim_number=5, compute_replication_time=True, compute_fork_directionality=True, compute_origin_positions=True, interval=None):\n",
    "    for cell_line in cell_lines:\n",
    "        for chr_number in chr_numbers:\n",
    "            chr_length = chr_lengths[chr_number - 1]  # Get the length of the chromosome\n",
    "            intervals = [(interval[0], interval[1])] if interval else [(start, min(start + 10000, chr_length)) for start in range(0, chr_length, 10000)]\n",
    "            for start, end in intervals:\n",
    "                process_bcs_output(\n",
    "                    cell_line=cell_line,\n",
    "                    chr_number=chr_number,\n",
    "                    chrpos_min=start,\n",
    "                    chrpos_max=end,\n",
    "                    fork_speed=fork_speed,\n",
    "                    resolution=resolution,\n",
    "                    scale_factor=scale_factor,\n",
    "                    sim_number=sim_number,\n",
    "                    compute_replication_time=compute_replication_time,\n",
    "                    compute_fork_directionality=compute_fork_directionality,\n",
    "                    compute_origin_positions=compute_origin_positions\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f38a9-20e1-4e9e-9662-6698983f39ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Interorigin distances #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47bb76cd-99d2-44e8-ad5f-0622dcdaaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interorigin_distances(cell_line, chr_number, chrpos_min, chrpos_max):\n",
    "    base_path = 'data'\n",
    "    \n",
    "    # Define file path for loading the origins\n",
    "    origins_path = os.path.join(base_path, 'whole-genome_origins', f'origin_positions_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt')\n",
    "    \n",
    "    # Load origins data from text file\n",
    "    if os.path.exists(origins_path):\n",
    "        with open(origins_path, 'r') as f:\n",
    "            origins_data = [list(map(int, line.strip().strip('[]').split())) for line in f]\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Origins data not found at {origins_path}\")\n",
    "    \n",
    "    # Compute interorigin distances for each simulation\n",
    "    interorigin_distances = []\n",
    "    for origins in origins_data:\n",
    "        origins_sorted = sorted(origins)\n",
    "        distances = np.diff(origins_sorted)\n",
    "        interorigin_distances.append(distances)\n",
    "    \n",
    "    # Define file path for saving the interorigin distances\n",
    "    iod_path = os.path.join(base_path, 'whole-genome_interorigin_distances', f'iod_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt')\n",
    "    \n",
    "    # Save interorigin distances to a text file\n",
    "    with open(iod_path, 'w') as f:\n",
    "        for distances in interorigin_distances:\n",
    "            f.write(f\"{list(distances)}\\n\")\n",
    "\n",
    "def compute_interorigin_intervals(cell_lines, chr_numbers, interval=None):\n",
    "    for cell_line in cell_lines:\n",
    "        for chr_number in chr_numbers:\n",
    "            chr_length = chr_lengths[chr_number - 1]  # Get the length of the chromosome\n",
    "            intervals = [(interval[0], interval[1])] if interval else [(start, min(start + 10000, chr_length)) for start in range(0, chr_length, 10000)]\n",
    "            for start, end in intervals:\n",
    "                compute_interorigin_distances(\n",
    "                    cell_line=cell_line,\n",
    "                    chr_number=chr_number,\n",
    "                    chrpos_min=start,\n",
    "                    chrpos_max=end\n",
    "                )\n",
    "\n",
    "def average_iod_data(cell_lines, chr_numbers, factor_min=5, show_per_cell_line=False):\n",
    "    all_iod_data = []\n",
    "    iod_data_per_cell_line = []\n",
    "\n",
    "    for cell_line in cell_lines:\n",
    "        cell_line_iod_data = []\n",
    "        for chr_number in chr_numbers:\n",
    "            chr_length = chr_lengths[chr_number - 1]\n",
    "            for start in range(0, chr_length, 10000):\n",
    "                end = min(start + 10000, chr_length)\n",
    "                iod_data = load_function_metrics(cell_line, chr_number, \"iod\", start, end, factor_min=factor_min)\n",
    "                cell_line_iod_data.extend(iod_data)\n",
    "        iod_data_per_cell_line.append(cell_line_iod_data)\n",
    "        all_iod_data.extend(cell_line_iod_data)\n",
    "\n",
    "    if show_per_cell_line:\n",
    "        return iod_data_per_cell_line\n",
    "    else:\n",
    "        return [all_iod_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3770db5-616c-45eb-bdcc-b3394e7f800b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### File joining functions ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3a807da-65ff-4919-bc1c-a920a0af5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_files(cell_line, chr_number, datatype, interval=10000):\n",
    "    all_data = []\n",
    "    max_length = chr_lengths[chr_number - 1]\n",
    "    \n",
    "    for start in range(0, max_length, interval):\n",
    "        end = min(start + interval, max_length)  # Ensure the end does not exceed max_length\n",
    "        file_name = f'data/whole-genome_{datatype}/fork_directionality_{cell_line}_chr[{chr_number}]_{start}-{end}.txt'\n",
    "        \n",
    "        if os.path.exists(file_name):\n",
    "            data = np.loadtxt(file_name, dtype=float)\n",
    "            all_data.append(data)\n",
    "        else:\n",
    "            print(f'Warning: {file_name} does not exist and will be skipped.')\n",
    "    \n",
    "    # Concatenate all data into a single array\n",
    "    if all_data:\n",
    "        concatenated_data = np.concatenate(all_data)\n",
    "    else:\n",
    "        concatenated_data = np.array([])\n",
    "\n",
    "    # Save concatenated data to a new file\n",
    "    output_file = f'data/whole-genome_{datatype}/fork_directionality_{cell_line}_chr[{chr_number}].txt'\n",
    "    np.savetxt(output_file, concatenated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3008c-d9bd-49d2-9b2f-972e94eff663",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Loading functions ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2ee3660-7fa6-4e62-b731-393edd0ea8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_function(cell_line, chr_number, load_type, replace_missingQ=True):\n",
    "    if load_type == 'time_data':\n",
    "        file_path = f'data/whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'time_sim':\n",
    "        file_path = f'data/whole-genome_timing_simulation/time_sim_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'error':\n",
    "        file_path = f'data/whole-genome_error/error_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'fire_rates':\n",
    "        file_path = f'data/whole-genome_firing_rates/fire_rates_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'forkd':\n",
    "        file_path = f'data/whole-genome_fork_directionality/fork_directionality_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'rna_seq':\n",
    "        file_path = f'data/rna-seq_files/rna_seq_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'gro_seq':\n",
    "        file_path = f'data/gro-seq_files/gro_seq_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'DNaseIHS':\n",
    "        file_path = f'data/DNaseIHS_files/DNaseIHS_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'chip_seq':\n",
    "        file_path = f'data/chip-seq_files/chip_seq_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'prom':\n",
    "        file_path = f'data/promoter_files/prom_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'prom_smooth':\n",
    "        file_path = f'data/promoter_files/prom_{cell_line}_chr[{chr_number}]_smooth.txt'\n",
    "    elif load_type == 'coding':\n",
    "        file_path = f'data/genome_regions/coding/coding_chr[{chr_number}]_smooth.txt'\n",
    "    elif load_type == 'speed_data':\n",
    "        file_path = f'data/fork_speed/speed_data_{cell_line}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'speed_sim':\n",
    "        file_path = f'data/fork_speed/speed_sim_{cell_line}_chr[{chr_number}].txt'\n",
    "        \n",
    "    if not os.path.exists(file_path):\n",
    "        return np.array([], dtype=int)\n",
    "    data = np.loadtxt(file_path, dtype=float)\n",
    "    if replace_missingQ:\n",
    "        missing_data_path = f'data/whole-genome_missing_data/missing_data_{cell_line}_chr[{chr_number}].txt'\n",
    "        if os.path.getsize(missing_data_path) > 0:\n",
    "            missing_positions = np.loadtxt(missing_data_path, dtype=int)\n",
    "        else:\n",
    "            missing_positions = np.array([], dtype=int) \n",
    "        data[missing_positions] = np.nan\n",
    "    return data\n",
    "\n",
    "def load_function_pos(chr_number, load_type, cell_line=None, site_letter='A', base='A', gene_name='WWOX'):\n",
    "    if load_type == 'centromeres':\n",
    "        file_path = f'data/genome_regions/centromeres/positions_centromeres_chr[{chr_number}].txt'\n",
    "    elif load_type == 'telomeres':\n",
    "        file_path = f'data/genome_regions/telomeres/positions_telomeres_chr[{chr_number}].txt'\n",
    "    elif load_type == 'fragile_sites':\n",
    "        file_path = f'data/genome_regions/fragile_sites/positions_fragile_site_{chr_number}{site_letter}.txt'\n",
    "    elif load_type == 'bases':\n",
    "        file_path = f'data/genome_regions/bases/positions_{base}_chr[{chr_number}].txt'\n",
    "    elif load_type == 'coding':\n",
    "        file_path = f'data/genome_regions/coding/codingpos_chr[{chr_number}].txt'\n",
    "    elif load_type == 'gene':\n",
    "        file_path = f'data/genome_regions/genes/{gene_name}_pos.txt'\n",
    "        \n",
    "    if not os.path.exists(file_path):\n",
    "        return np.array([], dtype=int)\n",
    "    data = np.loadtxt(file_path, dtype=int)\n",
    "    return data\n",
    "\n",
    "def load_function_metrics(cell_line, chr_number, load_type, chrpos_min, chrpos_max, factor_min=5, replace_missingQ=True):\n",
    "    if load_type == \"iod\":\n",
    "        file_path = f'data/whole-genome_interorigin_distances/iod_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt'\n",
    "        iod_data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                iod_values = list(map(float, line.strip().strip('[]').split(',')))\n",
    "                iod_data.extend([iod for iod in iod_values if iod >= factor_min])  # Filter IOD values\n",
    "        data = np.array(iod_data)\n",
    "        return data\n",
    "\n",
    "def load_missing_data(cell_line, chr_number):\n",
    "    file_path = f'data/whole-genome_missing_data/missing_data_{cell_line}_chr[{chr_number}].txt'\n",
    "    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "        data = np.loadtxt(file_path, dtype=int)\n",
    "    else:\n",
    "        data = np.array([], dtype=int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274fa0f-72f0-41a9-a1fe-1c826115bf8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Genome regions ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eac2454-c172-403d-aaec-151aecb6c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_data(cell_line, chr_numbers, load_type1, load_type2):\n",
    "    all_data1 = []\n",
    "    all_data2 = []\n",
    "    for chr_number in chr_numbers:\n",
    "        data1 = load_function(cell_line, chr_number, load_type1)\n",
    "        data2 = load_function(cell_line, chr_number, load_type2)\n",
    "        all_data1.extend(data1)\n",
    "        all_data2.extend(data2)\n",
    "    return [all_data1, all_data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87572b19-ee3d-4173-bc81-f2a6e32d62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centromeres and telomeres\n",
    "\n",
    "def gen_positions_centromere_telomeres(chr_number):\n",
    "    # Telomere positions (start and end 500 kb)\n",
    "    telomere_start = 500  # in kb\n",
    "    telomere_end_offset = 500  # in kb\n",
    "\n",
    "    # Centromere positions (in kb, hg38, approximate)\n",
    "    centromere_positions_hg38 = [\n",
    "        (121535, 124535), (92326, 95326), (90505, 93505), (49660, 52660),\n",
    "        (46406, 49406), (58830, 61830), (58054, 61054), (43839, 46839),\n",
    "        (47368, 50368), (39255, 42255), (51644, 54644), (34857, 37857),\n",
    "        (16000, 19000), (16000, 19000), (17000, 20000), (35336, 38336),\n",
    "        (22263, 25263), (15461, 18461), (24682, 27682), (26370, 29370),\n",
    "        (11288, 14288), (13000, 16000)\n",
    "    ]\n",
    "\n",
    "    # Provided chromosome lengths (in kb)\n",
    "    chromosome_lengths = [\n",
    "        249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365,\n",
    "        141214, 135535, 135007, 133852, 115170, 107350, 102532, 90355,\n",
    "        81196, 78078, 59129, 63026, 48130, 51305\n",
    "    ]\n",
    "\n",
    "    # Define additional positions to include telomeres and centromeres\n",
    "    length = chromosome_lengths[chr_number - 1]\n",
    "    centromere_start, centromere_end = centromere_positions_hg38[chr_number - 1]\n",
    "    positions_telomeres = np.concatenate([\n",
    "        np.arange(0, telomere_start),\n",
    "        np.arange(length - telomere_end_offset, length)\n",
    "    ])\n",
    "    positions_centromeres = np.arange(centromere_start, centromere_end)\n",
    "\n",
    "    # Save telomere_positions to a text file\n",
    "    np.savetxt(f'data/genome_regions/telomeres/positions_telomeres_chr[{chr_number}].txt', positions_telomeres, fmt='%d')\n",
    "\n",
    "    # Save centromere_positions to a text file\n",
    "    np.savetxt(f'data/genome_regions/centromeres/positions_centromeres_chr[{chr_number}].txt', positions_centromeres, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04f3555a-d3c5-48ea-b9d0-fcf1327e4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragile sites\n",
    "\n",
    "def gen_positions_fragile_sites(chr_number, site_letter):\n",
    "    # Load the CSV file\n",
    "    csv_path = 'data/genome_regions/fragile_sites/humCFS-fragile_sites.csv'\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    \n",
    "    positions_fragile_site = []\n",
    "\n",
    "    # Find the column corresponding to the given chromosome\n",
    "    col_index = chr_number - 1  # Chromosome 1 corresponds to column 0, and so on\n",
    "\n",
    "    if col_index >= df.shape[1]:\n",
    "        print(f\"Warning: Chromosome {chr_number} not found in the CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Find the row corresponding to the given site letter\n",
    "    row_index = ord(site_letter.upper()) - ord('A')  # 'A' corresponds to row 0, 'B' to row 1, and so on\n",
    "\n",
    "    if row_index >= df.shape[0]:\n",
    "        #print(f\"Warning: Site letter {site_letter} not found in the CSV file for chromosome {chr_number}.\")\n",
    "        return\n",
    "\n",
    "    # Extract the range in the form chrposmin-chrposmax\n",
    "    site_range = df.iloc[row_index, col_index]\n",
    "\n",
    "    if pd.isna(site_range):\n",
    "        #print(f\"Warning: No data for site {site_letter} on chromosome {chr_number}.\")\n",
    "        return\n",
    "\n",
    "    # Split the range into minimum and maximum positions\n",
    "    pos_min, pos_max = map(int, site_range.split('-'))\n",
    "\n",
    "    # Convert positions to kb\n",
    "    pos_min_kb = pos_min // 1000\n",
    "    pos_max_kb = pos_max // 1000\n",
    "\n",
    "    # Append the range as a numpy array\n",
    "    positions_fragile_site.append(np.arange(pos_min_kb, pos_max_kb))\n",
    "\n",
    "    # Flatten the list of arrays\n",
    "    flattened_positions = np.concatenate(positions_fragile_site)\n",
    "\n",
    "    # Save positions_fragile_site to a text file, with each value on a new line\n",
    "    np.savetxt(f'data/genome_regions/fragile_sites/positions_fragile_site_{chr_number}{site_letter}.txt', flattened_positions, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2484275d-0f9a-4aa5-a221-f1f331b4f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base regions\n",
    "\n",
    "def gen_positions_bases(local_genome_file, chr_lengths):\n",
    "    bases = ['A', 'T', 'G', 'C']\n",
    "    \n",
    "    output_dir = 'data/genome_regions/bases'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with gzip.open(local_genome_file, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            chr_number = record.id.lstrip(\"chr\")  # Removing 'chr' prefix\n",
    "            if chr_number.isdigit():\n",
    "                chr_number = int(chr_number)\n",
    "                if chr_number in range(1, 23):  # Assuming we only want chromosomes 1-22\n",
    "                    seq = str(record.seq).upper()  # Ensure sequence is uppercase\n",
    "                    base_files = {base: [] for base in bases}\n",
    "                    \n",
    "                    for kb in range(chr_lengths[chr_number-1]):\n",
    "                        position = kb * 1000  # 0-based position\n",
    "                        if position < len(seq):\n",
    "                            base_pair = seq[position]\n",
    "                            if base_pair in base_files:\n",
    "                                base_files[base_pair].append(kb)\n",
    "                    \n",
    "                    for base, locations in base_files.items():\n",
    "                        with open(os.path.join(output_dir, f'positions_{base}_chr[{chr_number}].txt'), 'w') as file:\n",
    "                            for loc in locations:\n",
    "                                file.write(f'{loc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c575726-1309-4e2d-87cd-8efeecc5c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate coding intervals and exact positions for each chromosome\n",
    "def generate_coding_intervals_and_positions():\n",
    "\n",
    "    # Input BigBed file and output directory\n",
    "    bigbed_path = r'data/genome_regions/coding/gencodeV45lift37.bb'\n",
    "    output_dir = r'data/genome_regions/coding/'\n",
    "    \n",
    "    # Open the BigBed file using pybigtools\n",
    "    bb = pybigtools.open(bigbed_path)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # List of chromosomes as strings (1-22)\n",
    "    chromosomes = [str(i) for i in range(1, 23)]\n",
    "    \n",
    "    # Loop over each chromosome\n",
    "    for i, chrom in enumerate(chromosomes):\n",
    "        \n",
    "        # Initialize a list representing the chromosome at 1kb resolution, with each position set to 0\n",
    "        chrom_data = [0] * chr_lengths[i]\n",
    "        \n",
    "        # List to store exact coding positions (in kb)\n",
    "        exact_positions = []\n",
    "        \n",
    "        # Query all records for the chromosome\n",
    "        for record in bb.records(f\"chr{chrom}\"):\n",
    "            chrom_start = record[0]\n",
    "            chrom_end = record[1]\n",
    "            fields = record[2:]  # Additional fields, including transcript class\n",
    "            \n",
    "            # Assuming transcriptClass is in a specific position\n",
    "            transcript_class = fields[17]\n",
    "            \n",
    "            # Only process coding transcripts\n",
    "            if transcript_class == 'coding':\n",
    "                # Mark positions as coding (1) for the corresponding 1kb intervals\n",
    "                for pos in range(chrom_start // 1000, min(chrom_end // 1000 + 1, chr_lengths[i])):\n",
    "                    chrom_data[pos] = 1\n",
    "                \n",
    "                # Store exact positions for coding intervals\n",
    "                for pos in range(chrom_start // 1000, chrom_end // 1000 + 1):\n",
    "                    exact_positions.append(pos)\n",
    "        \n",
    "        # Set output file for 1kb resolution data (0 and 1)\n",
    "        output_file_1kb = os.path.join(output_dir, f\"coding_chr[{chrom}].txt\")\n",
    "        \n",
    "        # Write the 1kb resolution data to the output file\n",
    "        with open(output_file_1kb, 'w') as f_out_1kb:\n",
    "            f_out_1kb.write(\"\\n\".join(map(str, chrom_data)))\n",
    "        \n",
    "        # Set output file for exact coding positions\n",
    "        output_file_positions = os.path.join(output_dir, f\"codingpos_chr[{chrom}].txt\")\n",
    "        \n",
    "        # Write the exact coding positions to the output file\n",
    "        with open(output_file_positions, 'w') as f_out_pos:\n",
    "            f_out_pos.write(\"\\n\".join(map(str, exact_positions)))\n",
    "\n",
    "def process_coding_file(chr_number):\n",
    "    # Load the original file\n",
    "    input_file = f\"data/genome_regions/coding/codingpos_chr[{chr_number}].txt\"\n",
    "    output_file = f\"data/genome_regions/coding/codingpos_chr[{chr_number}].txt\"\n",
    "    \n",
    "    # Read the file contents\n",
    "    with open(input_file, 'r') as file:\n",
    "        # Read each line, strip newlines, convert to integer, and store in a set to remove duplicates\n",
    "        data = set(int(line.strip()) for line in file)\n",
    "    \n",
    "    # Sort the unique values\n",
    "    sorted_data = sorted(data)\n",
    "    \n",
    "    # Write the sorted data back to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for value in sorted_data:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e10b33-356b-4207-9d07-0ac14e18522d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Replication timing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a49d406-3913-45b3-9a5d-b15b8ad1f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_plotf(cell_line, chr_number, chrpos_min, chrpos_max, scale_factor, file_name, spec_fileQ, saveQ, ax=None, show_ticks=True, show_title=True, simQ=False):\n",
    "    global time_data\n",
    "\n",
    "    # Data loading (Warning: requires saving data in fitting procedure)\n",
    "    # Choose between whole-genome files or particular simulation\n",
    "    if spec_fileQ:\n",
    "        time_data = np.loadtxt(f'data/whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt', dtype=float)\n",
    "        time_sim = np.loadtxt(f'data/whole-genome_timing_simulation/time_sim_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt', dtype=float)\n",
    "    else:\n",
    "        time_data = np.loadtxt(f'data/whole-genome_timing_data/time_data_{cell_line}_chr[{chr_number}].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "        time_sim = np.loadtxt(f'data/whole-genome_timing_simulation/time_sim_{cell_line}_chr[{chr_number}].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "\n",
    "    if simQ:\n",
    "        time_sim = np.loadtxt(f'data/whole-genome_timing_bcs/time_bcs_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt', dtype=float)\n",
    "    \n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    \n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(x, time_data, label='data', color='gray', linewidth=4, alpha=0.6)\n",
    "    ax.plot(x, time_sim, label='bcs', color='red', linewidth=4, alpha=0.6)\n",
    "    if show_title:\n",
    "        ax.set_title(cell_line + ' - Chromosome ' + str(chr_number))\n",
    "    ax.set_xlabel('Chromosome position (kb)' if show_title else None)\n",
    "    ax.set_ylabel('Time in S-phase (min)' if show_title else \"Replication time\")\n",
    "    ax.set_ylim(100 * scale_factor, 0)\n",
    "    ax.set_xlim(chrpos_min, chrpos_max)  # Ensure the x-axis covers the full range\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(axis='both', which='both', direction='out', bottom=show_ticks, labelbottom=show_ticks, left=show_ticks, labelleft=show_ticks)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "    \n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/plot_RT_' + file_name + '.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b0512-31da-41a6-84ac-097d757fbdf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### KDE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf735135-fd34-4147-b0bd-c65fffcfcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_kdes(data_list, labels, bw_adjust=1, saveQ=False, x_grid_size=1000, normalize=False, log_scale=False, x_min=None, x_max=None, plot_title=\"Relative density plots\", x_title=\"Error\", save_name=\"savedfile\"):\n",
    "    if log_scale:\n",
    "        # Filter out non-positive values for log scale\n",
    "        data_list = [data[data > 0] for data in data_list]\n",
    "        if x_min is None:\n",
    "            x_min = min(data.min() for data in data_list)\n",
    "        if x_max is None:\n",
    "            x_max = max(data.max() for data in data_list)\n",
    "        x = np.logspace(np.log10(x_min), np.log10(x_max), x_grid_size)\n",
    "    else:\n",
    "        if x_min is None:\n",
    "            x_min = min(data.min() for data in data_list)\n",
    "        if x_max is None:\n",
    "            x_max = max(data.max() for data in data_list)\n",
    "        x = np.linspace(x_min, x_max, x_grid_size)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "\n",
    "    # Compute and plot the KDEs\n",
    "    if normalize:\n",
    "        for data in data_list:\n",
    "            ax = sns.kdeplot(data, fill=True, bw_adjust=bw_adjust, log_scale=log_scale)#, alpha=.5)\n",
    "    else:\n",
    "        ax = sns.kdeplot(data_list, fill=True, bw_adjust=bw_adjust, log_scale=log_scale)#, alpha=.5)\n",
    "    handles = [mpatches.Patch(facecolor=color, label=label, alpha=0.5) for color, label in zip(plt.rcParams['axes.prop_cycle'].by_key()['color'], labels)]\n",
    "\n",
    "\n",
    "    \n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_title)\n",
    "    \n",
    "    plt.gca().yaxis.set_visible(False)  # Remove y-axis ticks\n",
    "    plt.ylabel('')  # Remove y-axis label\n",
    "    if log_scale:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.legend(handles=handles, loc='upper left')\n",
    "    if saveQ:\n",
    "        plt.savefig(f'figures/fig_kdeplot_{save_name}.pdf', bbox_inches='tight', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315a2d0-2517-4d74-b7d4-88b230084463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data vs data scatter plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa6e2754-f6fb-430d-81cc-3110c4eda6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modified_cmap(map_to_white):\n",
    "    viridis = plt.cm.viridis\n",
    "    newcolors = viridis(np.linspace(0, 1, 256))\n",
    "    if map_to_white:\n",
    "        white = np.array([1, 1, 1, 1])\n",
    "        newcolors[:1, :] = white\n",
    "    modified_cmap = mcolors.ListedColormap(newcolors)\n",
    "    return modified_cmap\n",
    "\n",
    "def plot_replication_data_vs_data(data, labels, colors, xmin=1e-15, xmax=1e5, ymin=0, ymax=500, sizep=0.1, title_x=\"Error\", title_y=\"Replication time (min)\",title=\"\",\n",
    "                                  log_x=True, log_y=False, use_density=True, dpi=100, map_to_white=False, invertyQ=False, saveQ=False):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    modified_cmap = create_modified_cmap(map_to_white)\n",
    "    \n",
    "    if use_density:\n",
    "        for (data1, data2), label, color in zip(data, labels, colors):\n",
    "            # Filter out NaN values\n",
    "            mask = ~np.isnan(data2) & ~np.isnan(data1)\n",
    "            data2 = np.array(data2)[mask]\n",
    "            data1 = np.array(data1)[mask]\n",
    "\n",
    "            # Rasterize the density artist for reduced file size\n",
    "            density = ScatterDensityArtist(ax, data2, data1, cmap=modified_cmap, dpi=dpi, rasterized=True)\n",
    "            ax.add_artist(density)\n",
    "\n",
    "        cbar = plt.colorbar(density, ax=ax)\n",
    "        cbar.ax.set_ylabel('Density')\n",
    "    else:\n",
    "        for (data1, data2), label, color in zip(data, labels, colors):\n",
    "            # Rasterize the scatter points for reduced file size\n",
    "            ax.scatter(data2, data1, s=0.02 if label == 'Whole-genome' else sizep, color=color, label=label, rasterized=True)\n",
    "\n",
    "        # Custom legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        new_handles = [plt.Line2D([], [], color=handle.get_facecolor()[0], marker='o', linestyle='', markersize=3) for handle in handles]\n",
    "        ax.legend(handles=new_handles, labels=labels)\n",
    "\n",
    "    # Set x-axis scale to log if log_x is True\n",
    "    if log_x:\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "    # Set y-axis scale to log if log_y is True\n",
    "    if log_y:\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "    else:\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "    if invertyQ:\n",
    "        ax.set_ylim(ax.get_ylim()[::-1])  # Invert y-axis only if not log scale\n",
    "\n",
    "    ax.set_xlim((xmin, xmax))\n",
    "    ax.set_aspect(aspect='auto')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(title_x)\n",
    "    ax.set_ylabel(title_y)\n",
    "\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/fig_scatter_density.pdf', bbox_inches='tight', transparent=True, dpi=dpi)  # Adjust dpi for saving\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd086089-6bde-44de-9c49-b7cf11360817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(load_type1, load_type2, cell_line, chr_numbers,\n",
    "                  show_all = True,\n",
    "                  show_telomeres=False, show_centromeres=False, show_fragile_sites=False,\n",
    "                  chr_number_fragile_sites=[1], site_letters=['A'],\n",
    "                  xmin=1e-15, xmax=1e-3, ymin=0, ymax=500, log_x=True, log_y=False, invertyQ=False,\n",
    "                  custom_positions=[], custom_labels=[\"\"], sizep=0.1,\n",
    "                  use_density=True, dpi=100, map_to_white=False, title=\"\", saveQ=False):\n",
    "\n",
    "    global all_data\n",
    "    \n",
    "    title_x = title_map[load_type2]\n",
    "    title_y = title_map[load_type1]\n",
    "\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    colours = []\n",
    "\n",
    "    all_data.append(generate_all_data(cell_line, chr_numbers, load_type1, load_type2))\n",
    "    labels.append(\"Whole-genome\")\n",
    "    #colours.append('#1f77b4')\n",
    "    colours.append('lightgrey')\n",
    "\n",
    "    for chr_number in chr_numbers:\n",
    "\n",
    "        if show_centromeres:\n",
    "            positions_centromeres = load_function_pos(chr_number, \"centromeres\")\n",
    "            data_centromeres = [[sublist[pos] for pos in positions_centromeres] for sublist in all_data[0]]\n",
    "            all_data.append(data_centromeres)\n",
    "            labels.append(\"\" if \"Centromeres\" in labels else \"Centromeres\")\n",
    "            colours.append('#1f77b4')\n",
    "    \n",
    "        if show_telomeres:\n",
    "            positions_telomeres = load_function_pos(chr_number, \"telomeres\")\n",
    "            data_telomeres = [[sublist[pos] for pos in positions_telomeres] for sublist in all_data[0]]\n",
    "            all_data.append(data_telomeres)\n",
    "            labels.append(\"\" if \"Telomeres\" in labels else \"Telomeres\")\n",
    "            colours.append('orange')\n",
    "\n",
    "        if len(custom_positions) != 0:\n",
    "            cmap = plt.get_cmap('tab20')\n",
    "            color_list = [cmap(i / 10) for i in range(len(custom_positions)+1)]\n",
    "            for i in range(0,len(custom_positions)):\n",
    "                positions_custom = np.array(custom_positions[i])\n",
    "                data_custom = [[sublist[pos] for pos in custom_positions[i]] for sublist in all_data[0]]\n",
    "                all_data.append(data_custom)\n",
    "                labels.append(custom_labels[i])\n",
    "                #colours.append('red')\n",
    "                colours.append(color_list[i+1])\n",
    "\n",
    "    for chr_number in chr_number_fragile_sites:\n",
    "\n",
    "        if show_fragile_sites:\n",
    "            for site_letter in site_letters:\n",
    "                positions_fragile_sites = load_function_pos(chr_number, \"fragile_sites\", site_letter=site_letter)\n",
    "                data_fragile_sites = [[sublist[pos] for pos in positions_fragile_sites] for sublist in all_data[0]]\n",
    "                all_data.append(data_fragile_sites)\n",
    "                labels.append(f'FRA{chr_number}{site_letter}')\n",
    "                colours.extend(list(plt.cm.autumn(np.linspace(0, .5, len(labels) - len(colours)))))\n",
    "                \n",
    "    if load_type1 == 'DNaseIHS':\n",
    "        all_data[0][0] = np.where(np.array(all_data[0][0]) <= 0, np.nan, all_data[0][0])\n",
    "\n",
    "    if show_all == False:\n",
    "        all_data = all_data[1:]\n",
    "        labels = labels[1:]\n",
    "        colours = colours[1:]\n",
    "\n",
    "    plot_replication_data_vs_data(all_data, labels, colours, xmin, xmax, ymin, ymax, sizep=sizep, title_x=title_x, title_y=title_y, title=title, log_x=log_x, log_y=log_y,\n",
    "                                  use_density=use_density, dpi=dpi, map_to_white=map_to_white, invertyQ=invertyQ, saveQ=saveQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90317c1e-c278-49a7-9850-f7e5c9014bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_scatter(speed_sim, speed_data, error, x_lim=100, y_lim=100, saveQ=False):\n",
    "    # Apply logarithmic scale to error, adding a small constant to avoid log(0)\n",
    "    log_error = np.log10(error + 1e-10)  # Add a small constant to avoid log(0)\n",
    "\n",
    "    # Create the scatter plot with green-to-red colormap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(speed_sim, speed_data, c=log_error, cmap=plt.get_cmap('RdYlGn_r'), \n",
    "                          s=.5, edgecolor=None, alpha=0.7, rasterized=True)  # Enable rasterization\n",
    "    \n",
    "    # Add color bar with green-to-red scale\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Error (log)', rotation=90, labelpad=15)\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('Simulated replication rate (kb/min)')\n",
    "    plt.ylabel('Observed replication rate (kb/min)')\n",
    "    plt.title('Error Heatmap (Green to Red)')\n",
    "    \n",
    "    # Set x and y axis limits\n",
    "    plt.xlim(1.2, x_lim)\n",
    "    plt.ylim(0, y_lim)\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/ratescatter.pdf', bbox_inches='tight', transparent=True, dpi=300)  # Use rasterized save\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "283f4f5b-bc66-42b9-85a4-c05ddf0716c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_maxima_filter_by_region(data_error, data_time,\n",
    "                                       point1=(0.01, 100), point2=(0.1, 500),\n",
    "                                       point3=(0.1, 100), point4=(1, 500)):\n",
    "    local_maxima_positions = []\n",
    "\n",
    "    # Step 1: Identify all local maxima\n",
    "    for i in range(1, len(data_error) - 1):\n",
    "        if data_error[i-1] < data_error[i] > data_error[i+1]:\n",
    "            local_maxima_positions.append(i)\n",
    "\n",
    "    # Step 2: Filter by the defined subregion\n",
    "    filtered_positions = []\n",
    "\n",
    "    # Line equations calculations\n",
    "    def line_equation(pointA, pointB):\n",
    "        # Calculate slope and intercept\n",
    "        slope = (pointB[1] - pointA[1]) / (pointB[0] - pointA[0])\n",
    "        intercept = pointA[1] - slope * pointA[0]\n",
    "        return lambda x: slope * x + intercept\n",
    "\n",
    "    # Create line functions from points\n",
    "    line1 = line_equation(point1, point2)\n",
    "    line2 = line_equation(point3, point4)\n",
    "\n",
    "    # Filtering based on subregion defined by the lines\n",
    "    for pos in local_maxima_positions:\n",
    "        x_value = data_error[pos]\n",
    "        y_value = data_time[pos]\n",
    "        # Check if the position satisfies both inequalities\n",
    "        if max(line2(x_value),0) <= y_value <= min(line1(x_value),300):\n",
    "            filtered_positions.append(pos)\n",
    "\n",
    "    return filtered_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41c91d8e-5b2c-40e0-98ba-65e503007583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_scatter(cell_line, chr_numbers, genes, saveQ=False):\n",
    "    custom_labels = genes\n",
    "\n",
    "    # Colors for the scatter plot\n",
    "    colors = plt.get_cmap('tab10').colors  # Use a colormap to get different colors\n",
    "    \n",
    "    # Initialize a list to store the lists of pairs (error[i], time_data[i])\n",
    "    gene_data_pairs = []\n",
    "    \n",
    "    # Loop through the chromosomes and genes\n",
    "    for i in range(len(chr_numbers)):\n",
    "        # Load positions for the gene on the given chromosome\n",
    "        positions = load_function_pos(chr_numbers[i], 'gene', gene_name=genes[i])\n",
    "        \n",
    "        # Load the time_data and error data for those positions\n",
    "        time_data = load_function(cell_line, chr_numbers[i], 'time_data')[positions]\n",
    "        error = load_function(cell_line, chr_numbers[i], 'error')[positions]\n",
    "        \n",
    "        # Create a list of pairs (error[i], time_data[i]) for this gene\n",
    "        pairs = list(zip(error, time_data))\n",
    "        gene_data_pairs.append(pairs)\n",
    "    \n",
    "    # Create the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # Loop through the gene data pairs and plot each gene's data\n",
    "    for i, gene_data in enumerate(gene_data_pairs):\n",
    "        error_vals, time_vals = zip(*gene_data)  # Unzip the pairs into error and time data\n",
    "        ax.scatter(error_vals, time_vals, color=colors[i % len(colors)], \n",
    "                    label=genes[i], alpha=0.7, s=1, rasterized=True)  # Rasterized scatter points\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Error (Log Scale)')\n",
    "    ax.set_ylabel('Replication Time (min)')\n",
    "    ax.set_xlim(1e-4, 1e4)\n",
    "    ax.set_title('')\n",
    "    \n",
    "    # Invert the y-axis\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Set x-axis to logarithmic scale\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "    # Set scientific notation for log scale tick labels\n",
    "    ax.xaxis.set_major_formatter(ticker.LogFormatterMathtext())\n",
    "    \n",
    "    # Create a custom legend with larger marker sizes\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = [plt.Line2D([], [], marker='o', color=colors[i % len(colors)], linestyle='None', markersize=5)\n",
    "                   for i in range(len(handles))]\n",
    "    ax.legend(new_handles, labels, title='Large genes')\n",
    "    \n",
    "    if saveQ:\n",
    "        plt.savefig('figures/scatter_genes.pdf', bbox_inches='tight', transparent=True, dpi=300)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc484f3-f311-4778-84e2-0f858ec76102",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Firing rate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e045657b-7d67-4f12-9e4a-3f5051f533e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_plotf(cell_line, chr_numbers, resolution, file_name, saveQ, ax=None, aspect_ratio=(10, 6), replace_missing_with_nan=True, show_ticks=True, show_title=True):\n",
    "\n",
    "    # Chromosome lengths in kb (1 kb resolution)\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, 135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, axes = plt.subplots(len(chr_numbers), 1, figsize=aspect_ratio, sharey=True)\n",
    "    else:\n",
    "        axes = [ax]  # Ensure axes is a list even if it's just one subplot\n",
    "    \n",
    "    for idx, chr_number in enumerate(chr_numbers):\n",
    "        # Data loading: Read firing rates from a text file\n",
    "        firing_rates_file_path = f'data/whole-genome_firing_rates/fire_rates_{cell_line}_chr[{chr_number}].txt'\n",
    "        firing_rates = np.loadtxt(firing_rates_file_path, dtype=float)\n",
    "\n",
    "        if replace_missing_with_nan:\n",
    "            missing_data_path = f'data/whole-genome_missing_data/missing_data_{cell_line}_chr[{chr_number}].txt'\n",
    "            missing_positions = np.loadtxt(missing_data_path, dtype=int)\n",
    "            firing_rates[missing_positions] = np.nan\n",
    "\n",
    "        # Generate chromosome positions in Mb\n",
    "        x = np.linspace(0, chr_lengths[chr_number - 1] / 1000, len(firing_rates))  # Chromosome positions in Mb\n",
    "\n",
    "        # Plotting\n",
    "        ax = axes[idx] if len(chr_numbers) > 1 else axes[0]\n",
    "        ax.plot(x, firing_rates, color='#1f77b4', linewidth=2, alpha=.9)\n",
    "        \n",
    "        if idx == 0 and show_title:\n",
    "            ax.set_title(f'{cell_line}')\n",
    "        if idx == len(chr_numbers) - 1:\n",
    "            if show_ticks:\n",
    "                ax.set_xlabel('Chromosome position (Mb)')\n",
    "                ax.set_xticks(np.arange(0, chr_lengths[0] / 1000, 20))  # Set x-axis ticks to show every 20 Mb\n",
    "        else:\n",
    "            ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)  # Remove x-axis ticks and labels for all but the last plot\n",
    "        \n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(10**-12, 10**-3)\n",
    "        ax.set_xlim(0, chr_lengths[0] / 1000)  # Set x-axis limit to the largest chromosome length in Mb\n",
    "        ax.tick_params(axis='both', which='both', direction='out')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "        \n",
    "        # Add chromosome number on the top right corner with a transparent box\n",
    "        ax.text(0.995, 0.93, f'chr {chr_number}', transform=ax.transAxes, \n",
    "                fontsize=12, verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(facecolor='white', alpha=0., edgecolor='none'))\n",
    "        \n",
    "        ax.grid(False)  # Remove grid for each plot\n",
    "\n",
    "    # Add a shared y-axis label if no axis is provided\n",
    "    if ax is None:\n",
    "\n",
    "        fig.text(0.065, 0.5, 'Firing rate', va='center', rotation='vertical')\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.05, hspace=0.15)  # Adjust margins and spacing\n",
    "\n",
    "    # Save plot if saveQ is True\n",
    "    if saveQ:\n",
    "        plt.savefig(f'figures/fig_plot_fire_signatures_{cell_line}.pdf', bbox_inches='tight', transparent=True, dpi=300)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab3000a4-f985-4f62-bae0-577d56f148cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_plotf2(cell_line, chr_number, chrpos_min, chrpos_max, file_name, saveQ, ax=None, show_ticks=True, show_title=True):\n",
    "    global fire_data\n",
    "\n",
    "    # Data loading\n",
    "    fire_data = np.loadtxt('data/whole-genome_firing_rates/fire_rates_' + cell_line + '_chr[' + str(chr_number) + '].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(x, fire_data, color='#1f77b4', linewidth=2, alpha=.9)\n",
    "    if show_title:\n",
    "        ax.set_title(cell_line + ' - Chromosome ' + str(chr_number))\n",
    "    ax.set_xlabel('Chromosome position (kb)' if show_title else None)\n",
    "    ax.set_ylabel('Firing rate' if show_title else \"Firing\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(10**-12, 10**-3)\n",
    "    ax.set_xlim(chrpos_min, chrpos_max)  # Ensure the x-axis covers the full range\n",
    "    ax.tick_params(axis='both', which='both', direction='out', bottom=show_ticks, labelbottom=show_ticks, left=show_ticks, labelleft=show_ticks)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        \n",
    "    # Set logarithmic ticks for y-axis\n",
    "    ax.yaxis.set_major_formatter(LogFormatterMathtext())\n",
    "    ax.yaxis.set_minor_formatter(LogFormatterMathtext())\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/plot_fire_' + file_name + '.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717de5e-f5fd-4851-9bc0-79c50dc3f51c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Error plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7bdb482-003b-421c-aefd-5ba6b49617ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plotf(cell_line, chr_number, chrpos_min, chrpos_max, file_name, saveQ, ax=None, show_ticks=True, show_title=True):\n",
    "    global error_data\n",
    "\n",
    "    # Data loading\n",
    "    error_data = np.loadtxt('data/whole-genome_error/error_' + cell_line + '_chr[' + str(chr_number) + '].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(x, error_data, color='#ff7f0e', linewidth=2, alpha=.9)\n",
    "    if show_title:\n",
    "        ax.set_title(cell_line + ' - Chromosome ' + str(chr_number))\n",
    "    ax.set_xlabel('Chromosome position (kb)' if show_title else None)\n",
    "    ax.set_ylabel('Error' if show_title else \"Error\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(10**-12, 10**6)\n",
    "    ax.set_xlim(chrpos_min, chrpos_max)  # Ensure the x-axis covers the full range\n",
    "    ax.tick_params(axis='both', which='both', direction='out', bottom=show_ticks, labelbottom=show_ticks, left=show_ticks, labelleft=show_ticks)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        \n",
    "    # Set logarithmic ticks for y-axis\n",
    "    ax.yaxis.set_major_formatter(LogFormatterMathtext())\n",
    "    ax.yaxis.set_minor_formatter(LogFormatterMathtext())\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/plot_error_' + file_name + '.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb9d79fa-cadc-4b17-9619-f1bfea5981a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_goodness_of_fit(chr_number, saveQ, ax=None, cell_lines=None, chrpos_min=0, chrpos_max=10, alld=True, base_path='data/', shift_param=1.0):\n",
    "    global spaced_data, missing_data\n",
    "    \n",
    "    if cell_lines is None:\n",
    "        cell_lines_BigWig = [\"HeLa-S3\",\"BJ1\",\"IMR90\",\"HUVEC\",\"K562\",\"GM12878\",\"HepG2\",\"MCF-7\"]\n",
    "        cell_lines_HighRes = [\"H1\",\"H9\",\"HCT\"]\n",
    "        cell_lines = cell_lines_BigWig + cell_lines_HighRes\n",
    "\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, 135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "    num_positions = chr_lengths[chr_number - 1]\n",
    "    num_cell_lines = len(cell_lines)\n",
    "\n",
    "    # Placeholder for goodness of fit data (use actual data from your model)\n",
    "    goodness_of_fit = [load_function(cell_line, chr_number, 'error') for cell_line in cell_lines]\n",
    "\n",
    "    # Apply shifted log transformation\n",
    "    transformed_goodness_of_fit = [np.log1p(data + shift_param) for data in goodness_of_fit]\n",
    "\n",
    "    # Normalize the transformed data to [0, 1] range\n",
    "    min_val = np.nanmin(transformed_goodness_of_fit)\n",
    "    max_val = np.nanmax(transformed_goodness_of_fit)\n",
    "    normalized_goodness_of_fit = [(data - min_val) / (max_val - min_val) for data in transformed_goodness_of_fit]\n",
    "\n",
    "    # Create a custom colormap for vivid red to vivid green\n",
    "    cmap = plt.get_cmap('RdYlGn_r')  # Note the '_r' to reverse the colormap\n",
    "\n",
    "    # Create a colormap that includes gray for the \"no data\" regions\n",
    "    colors = cmap(np.linspace(0, 1, 256))\n",
    "    colormap_gray = np.array([[0., 0., 0., 0.17]])  # RGBA for gray in colormap\n",
    "    new_colors = np.vstack((colors, colormap_gray))\n",
    "    extended_cmap = ListedColormap(new_colors)\n",
    "\n",
    "    if not alld:\n",
    "        normalized_goodness_of_fit = [i[chrpos_min:chrpos_max] for i in normalized_goodness_of_fit]\n",
    "        num_positions = chrpos_max - chrpos_min\n",
    "        x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    # Create the spaced data array with triplicates and NaN rows\n",
    "    spaced_data = np.full((num_cell_lines * 4 - 1, num_positions), np.nan)\n",
    "    for i in range(num_cell_lines):\n",
    "        spaced_data[i * 4] = normalized_goodness_of_fit[i]\n",
    "        spaced_data[i * 4 + 1] = normalized_goodness_of_fit[i]\n",
    "        spaced_data[i * 4 + 2] = normalized_goodness_of_fit[i]\n",
    "\n",
    "    # Load missing data and update goodness_of_fit\n",
    "    for i, cell_line in enumerate(cell_lines):\n",
    "        missing_data = load_missing_data(cell_line, chr_number) \n",
    "        if not alld:\n",
    "            #missing_data = list(set(missing_data) & set(range(chrpos_min, chrpos_max)))\n",
    "            missing_data = [i - chrpos_min for i in range(chrpos_min, chrpos_max) if i in missing_data]\n",
    "        spaced_data[i * 4, missing_data] = 256  # Mark missing data positions with index for gray\n",
    "        spaced_data[i * 4 + 1, missing_data] = 256\n",
    "        spaced_data[i * 4 + 2, missing_data] = 256\n",
    "\n",
    "    # Avoiding the maximum value being exactly 1 by subtracting a small epsilon value\n",
    "    spaced_data0 = spaced_data\n",
    "    spaced_data = np.clip(spaced_data * 255, 0, 255 - 1)  # Normalize to 0-255 range\n",
    "    spaced_data[spaced_data0 == 256] = 256  # Ensure missing data stays at 256\n",
    "\n",
    "    # Normalize data for colormap\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, .5*num_cell_lines))\n",
    "        \n",
    "    cax = ax.imshow(spaced_data, aspect='auto', cmap=extended_cmap, interpolation='nearest', vmin=0, vmax=255)\n",
    "\n",
    "    # Add color bar to the right and match height of the bars on the left\n",
    "    if alld:\n",
    "        cbar = fig.colorbar(cax, orientation='vertical', pad=0.02)\n",
    "        cbar.set_label('Normalized error' if alld else None)\n",
    "        cbar.set_ticks(np.linspace(0, 255, 6))\n",
    "        cbar.set_ticklabels(np.round(np.linspace(0, 1, 6), 2))\n",
    "\n",
    "    # Set ticks and labels\n",
    "    yticks_positions = np.arange(1, num_cell_lines * 4, 4)\n",
    "    ax.set_yticks(yticks_positions if alld else [])\n",
    "    ax.set_yticklabels(cell_lines if alld else [])\n",
    "    xtick_positions = np.arange(0, num_positions, 20000)\n",
    "    xtick_labels = (xtick_positions / 1000).astype(int)\n",
    "    ax.set_xticks(xtick_positions if alld else [])\n",
    "    ax.set_xticklabels(xtick_labels if alld else [])\n",
    "    ax.set_xlabel('Chromosome position (Mb)' if alld else None)\n",
    "\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Add a gray square and text for \"Missing data\" in the top right corner\n",
    "    if alld:\n",
    "        ax.text(0, 1.04, f'Chromosome {chr_number}', transform=ax.transAxes, fontsize=7, verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor=\"none\", edgecolor='none'))\n",
    "        ax.text(1, 1.04, 'Missing data', transform=ax.transAxes, fontsize=7, verticalalignment='top', horizontalalignment='right', bbox=dict(facecolor=\"none\", edgecolor='none'))\n",
    "        ax.add_patch(plt.Rectangle((.924, 1.02), 0.008, 0.02, transform=ax.transAxes, color=[0., 0., 0., 0.17], clip_on=False))\n",
    "\n",
    "    if saveQ:\n",
    "        plt.savefig(f'figures/fig_goodness_of_fit_chr[{chr_number}].pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ae9649c-845f-4a4e-ab89-0d58a7b38beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE plots\n",
    "def read_mse_file(file_path, num_elements=100):\n",
    "    mse_values = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                mse_values.append(float(line.split(':')[-1].strip()))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return mse_values[:num_elements]\n",
    "\n",
    "def average_mse_across_chromosomes(cell_line, num_elements=100):\n",
    "    num_chromosomes = 22  # Assuming 24 chromosomes\n",
    "    all_mse_values = []\n",
    "\n",
    "    for chr_number in range(1, num_chromosomes + 1):\n",
    "        file_path = f'data/whole-genome_mse/mse_{cell_line}_chr[{chr_number}].txt'\n",
    "        mse_values = read_mse_file(file_path, num_elements)\n",
    "        if mse_values:\n",
    "            all_mse_values.append(mse_values)\n",
    "    \n",
    "    if not all_mse_values:\n",
    "        return []\n",
    "\n",
    "    # Convert list to numpy array for easy processing\n",
    "    all_mse_values = np.array(all_mse_values)\n",
    "    # Compute the mean across chromosomes for each iteration\n",
    "    averaged_mse = np.mean(all_mse_values, axis=0)\n",
    "    return averaged_mse\n",
    "\n",
    "def plot_averaged_mse(cell_lines, num_elements=100, log_scale=False, saveQ=False):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for cell_line in cell_lines:\n",
    "        averaged_mse = average_mse_across_chromosomes(cell_line, num_elements)\n",
    "        if len(averaged_mse) == 0:\n",
    "            print(f\"No data found for {cell_line}.\")\n",
    "            continue\n",
    "        iterations = np.arange(1, len(averaged_mse) + 1)\n",
    "        plt.plot(iterations, averaged_mse, label=f'{cell_line}')\n",
    "\n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel('Averaged MSE')\n",
    "    plt.ylim(100,1600)\n",
    "    \n",
    "    if log_scale:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    plt.title('Averaged MSE Over Iterations for Different Cell Lines')\n",
    "    plt.grid(False)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/mseplots.pdf', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ff973-cce2-440f-8ffb-7dc73e1a66db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fork directionality plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1810da7-ce5e-407c-bc46-6dde078d8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forkd_plotf(cell_line, chr_number, chrpos_min, chrpos_max, file_name, spec_fileQ, saveQ, ax=None, show_ticks=True, show_title=True):\n",
    "    global time_data\n",
    "\n",
    "    # Data loading (Warning: requires saving data in fitting procedure)\n",
    "    # Choose between whole-genome files or particular simulation\n",
    "    if spec_fileQ:\n",
    "        forkd_data = np.loadtxt(f'data/whole-genome_fork_directionality/fork_directionality_{cell_line}_chr[{chr_number}]_{chrpos_min}-{chrpos_max}.txt', dtype=float)\n",
    "    else:\n",
    "        forkd_data = np.loadtxt(f'data/whole-genome_fork_directionality/fork_directionality_{cell_line}_chr[{chr_number}].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    \n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(x, forkd_data, label='', color='black', linewidth=2, alpha=0.6)\n",
    "    if show_title:\n",
    "        ax.set_title(cell_line + ' - Chromosome ' + str(chr_number))\n",
    "    ax.set_xlabel('Chromosome position (kb)' if show_title else None)\n",
    "    ax.set_ylabel('Fork directionality' if show_title else \"Fork dir.\")\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_xlim(chrpos_min, chrpos_max)  # Ensure the x-axis covers the full range\n",
    "    #ax.legend(loc='lower right')<s\n",
    "    ax.grid(True)\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(axis='both', which='both', direction='out', bottom=show_ticks, labelbottom=show_ticks, left=show_ticks, labelleft=show_ticks)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "    \n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/plot_forkd_' + file_name + '.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7d648-9553-41bc-8739-24c2357a3836",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### RNA-Seq plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9f57557-bd5c-4184-8ff4-257c82da5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rna_seq_plotf(cell_line, chr_number, chrpos_min, chrpos_max, file_name, saveQ, ax=None, show_ticks=True, show_title=True):\n",
    "\n",
    "    # Data loading\n",
    "    rna_seq_data = np.loadtxt('data/rna-seq_files/rna_seq_' + cell_line + '_chr[' + str(chr_number) + '].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(x, rna_seq_data, color='black', linewidth=1, alpha=.9)\n",
    "    if show_title:\n",
    "        ax.set_title(cell_line + ' - Chromosome ' + str(chr_number))\n",
    "    ax.set_xlabel('Chromosome position (kb)' if show_title else None)\n",
    "    ax.set_ylabel('Transcription levels (RNA-Seq)' if show_title else \"RNA-Seq\")\n",
    "    #ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_xlim(chrpos_min, chrpos_max)  # Ensure the x-axis covers the full range\n",
    "    ax.tick_params(axis='both', which='both', direction='out', bottom=show_ticks, labelbottom=show_ticks, left=show_ticks, labelleft=show_ticks)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        \n",
    "    # Set logarithmic ticks for y-axis\n",
    "    ax.yaxis.set_major_formatter(LogFormatterMathtext())\n",
    "    ax.yaxis.set_minor_formatter(LogFormatterMathtext())\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/plot_rna_seq_' + file_name + '.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b928f3-a8ab-4c28-b4f1-38b86ace83aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### GRO-Seq plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21abd9fd-33c2-4b9e-86a7-e2e9ae296b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gro_seq_plotf(cell_line, chr_number, chrpos_min, chrpos_max, file_name, saveQ, ax=None, show_ticks=True, show_title=True):\n",
    "\n",
    "    # Data loading\n",
    "    gro_seq_data = np.loadtxt('data/gro-seq_files/gro_seq_' + cell_line + '_chr[' + str(chr_number) + '].txt', dtype=float)[chrpos_min:chrpos_max]\n",
    "    x = np.linspace(chrpos_min, chrpos_max, chrpos_max - chrpos_min)  # Chromosome positions\n",
    "\n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(x, np.log1p(gro_seq_data), color='black', linewidth=1, alpha=.9)\n",
    "    if show_title:\n",
    "        ax.set_title(cell_line + ' - Chromosome ' + str(chr_number))\n",
    "    ax.set_xlabel('Chromosome position (kb)' if show_title else None)\n",
    "    ax.set_ylabel('Transcription levels (GRO-Seq)' if show_title else \"GRO-Seq\")\n",
    "    #ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 5)\n",
    "    ax.set_xlim(chrpos_min, chrpos_max)  # Ensure the x-axis covers the full range\n",
    "    ax.tick_params(axis='both', which='both', direction='out', bottom=show_ticks, labelbottom=show_ticks, left=show_ticks, labelleft=show_ticks)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        \n",
    "    # Set logarithmic ticks for y-axis\n",
    "    ax.yaxis.set_major_formatter(LogFormatterMathtext())\n",
    "    ax.yaxis.set_minor_formatter(LogFormatterMathtext())\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/plot_gro_seq_' + file_name + '.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b9eda-0fd0-43e2-ab1d-3d4f15038a75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Ideogram plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cbdfb19-d0cb-4b73-a9e2-35fc802f3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_genome(cell_line, chr_number, chrpos_min, chrpos_max,\n",
    "                show_genes_allQ=True, show_genes_bandsQ=True, show_genesQ=False,\n",
    "                show_rt_plotQ=True, show_fire_plotQ=True, show_forkd_plotQ=False, show_error_plotQ=True, show_rna_seq_plotQ=False, show_gro_seq_plotQ=False,\n",
    "                show_error_heat_plotQ=True,\n",
    "                show_axisQ=True, saveQ=False):\n",
    "    chrom = f\"chr{chr_number}\"\n",
    "    start = chrpos_min * 1000\n",
    "    end = chrpos_max * 1000\n",
    "\n",
    "    chr_lengths = [249251, 243200, 198023, 191155, 180916, 171116, 159139, 146365, 141214, 135535, 135007, 133852, 115170, 107350, 102532, 90355, 81196, 78078, 59129, 63026, 48130, 51305]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10), dpi=150)\n",
    "\n",
    "    fig.suptitle(f\"{cell_line} - Chromosome {chr_number}\")\n",
    "\n",
    "    height_ratios0 = [0.1, 0.1, 0.05, .2, .5, .2, .2, .2, .3, .3, .1, 0., 1]\n",
    "    show_components = [show_genes_allQ, show_genes_allQ, show_genes_bandsQ, show_genesQ, show_rt_plotQ, show_fire_plotQ, show_forkd_plotQ, show_error_plotQ, show_rna_seq_plotQ, show_gro_seq_plotQ, show_error_heat_plotQ, show_axisQ, True]\n",
    "    height_ratios = [height_ratios0[i] for i in range(len(height_ratios0)) if show_components[i]]\n",
    "\n",
    "    gs_i = -1\n",
    "\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=len(height_ratios),\n",
    "        ncols=3,\n",
    "        width_ratios=[2, 20, 2],\n",
    "        height_ratios=height_ratios,\n",
    "        hspace=0.01,\n",
    "        left=0.01,\n",
    "        right=0.99,\n",
    "        top=0.94,\n",
    "    )\n",
    "\n",
    "    # Add the full chromosome ideogram\n",
    "    if show_genes_allQ:\n",
    "        gs_i += 1\n",
    "        all_chrom_ax = fig.add_subplot(gs[gs_i, 1])\n",
    "        all_chrom_ax.axis(\"off\")\n",
    "        all_chrom_ax.set_xticks([])\n",
    "        pyideogram.ideogramh(chrom, ax=all_chrom_ax)\n",
    "        \n",
    "        # Draw a red rectangle on top of the region depicted in the full chromosome ideogram\n",
    "        rect_start = start  # Start position in base pairs\n",
    "        rect_end = end  # End position in base pairs\n",
    "        rectangle_thickness = 3  # Set the thickness of the rectangle outline\n",
    "        all_chrom_ax.add_patch(plt.Rectangle((rect_start, -0.5), rect_end - rect_start, 1, edgecolor='red', facecolor='none', linewidth=rectangle_thickness, clip_on=False))\n",
    "        \n",
    "        # Draw lines from the bottom corners of the rectangle\n",
    "        #all_chrom_ax.plot([rect_start, -chr_lengths[chr_number-1] * 1e3 * (1/5.25)], [-0.5, -2], color='black', linewidth=1, linestyle='-', clip_on=False)\n",
    "        #all_chrom_ax.plot([rect_end, chr_lengths[chr_number-1] * 1e3+chr_lengths[chr_number-1] * 1e3 * (1/5.3)], [-0.5, -2], color='black', linewidth=1, linestyle='-', clip_on=False)\n",
    "\n",
    "        gs_i += 1\n",
    "        empty_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        empty_ax.axis(\"off\")\n",
    "        empty_ax.tick_params(labelbottom=False)\n",
    "        #empty_ax.plot([rect_start, -chr_lengths[chr_number-1] * 1e3 * (1/5.25)], [-0.5, -2], color='black', linewidth=1, linestyle='-', clip_on=False)\n",
    "\n",
    "    # Add the zoomed ideogram within the same interval\n",
    "    if show_genes_bandsQ:\n",
    "        gs_i += 1\n",
    "        interval_ideogram_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        interval_ideogram_ax.axis(\"off\")\n",
    "        interval_ideogram_ax.set_xlim(start, end)\n",
    "        interval_ideogram_ax.set_xticks([])\n",
    "        pyideogram.ideogramh(chrom, ax=interval_ideogram_ax, names=True)\n",
    "        zoom_ax = interval_ideogram_ax\n",
    "\n",
    "    # Add the gene track plot\n",
    "    if show_genesQ:\n",
    "        gs_i += 1\n",
    "        gene_track_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        pyideogram.genetrack(\n",
    "            f\"{chrom}:{start}-{end}\",\n",
    "            ax=gene_track_ax,\n",
    "            textlane=True,\n",
    "            transcriptstyle=\"arrowed\",\n",
    "            exonstyle=\"Box\",\n",
    "        )\n",
    "        # Set genome ticks on the gene track plot\n",
    "        pyideogram.set_genome_xticks(gene_track_ax)\n",
    "        # Remove axis labels and ticks for the gene track plot\n",
    "        gene_track_ax.axis(\"on\")\n",
    "        gene_track_ax.set_xticks([])\n",
    "        gene_track_ax.set_ylabel('Genes')\n",
    "        gene_track_ax.tick_params(labelbottom=False)\n",
    "        if not show_genes_bandsQ:\n",
    "            zoom_ax = gene_track_ax\n",
    "\n",
    "    # Add RT plot\n",
    "    if show_rt_plotQ:\n",
    "        gs_i += 1\n",
    "        rt_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        rt_plotf(cell_line, chr_number, chrpos_min, chrpos_max, 6, 'example_file', False, False, ax=rt_ax, show_ticks=False, show_title=False)\n",
    "\n",
    "    # Add firing plot\n",
    "    if show_fire_plotQ:\n",
    "        gs_i += 1\n",
    "        fire_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        fire_plotf2(cell_line, chr_number, chrpos_min, chrpos_max, 'example_file', False, ax=fire_ax, show_ticks=False, show_title=False)\n",
    "\n",
    "    # Add fork directionality plot\n",
    "    if show_forkd_plotQ:\n",
    "        gs_i += 1\n",
    "        forkd_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        forkd_plotf(cell_line, chr_number, chrpos_min, chrpos_max, 'example_file', False, False, ax=forkd_ax, show_ticks=False, show_title=False)\n",
    "\n",
    "    # Add the error plot\n",
    "    if show_error_plotQ:\n",
    "        gs_i += 1\n",
    "        error_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        error_plotf(cell_line, chr_number, chrpos_min, chrpos_max, 'example_file', False, ax=error_ax, show_ticks=False, show_title=False)\n",
    "\n",
    "    # Add the RNA-Seq plot\n",
    "    if show_rna_seq_plotQ:\n",
    "        gs_i += 1\n",
    "        rna_seq_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        rna_seq_plotf(cell_line, chr_number, chrpos_min, chrpos_max, 'example_file', False, ax=rna_seq_ax, show_ticks=False, show_title=False)\n",
    "\n",
    "    # Add the GRO-Seq plot\n",
    "    if show_gro_seq_plotQ:\n",
    "        gs_i += 1\n",
    "        gro_seq_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        gro_seq_plotf(cell_line, chr_number, chrpos_min, chrpos_max, 'example_file', False, ax=gro_seq_ax, show_ticks=False, show_title=False)\n",
    "    \n",
    "    # Add the error heat plot\n",
    "    if show_error_heat_plotQ:\n",
    "        gs_i += 1\n",
    "        error_heat_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        error_heat_ax.set_ylabel('Error')\n",
    "        plot_goodness_of_fit(chr_number, False, ax=error_heat_ax, cell_lines=[cell_line], chrpos_min=chrpos_min, chrpos_max=chrpos_max, alld=False)\n",
    "\n",
    "    # Add a new row showing just the x-axis with the ticks\n",
    "    if show_axisQ:\n",
    "        gs_i += 1\n",
    "        x_ticks_ax = fig.add_subplot(gs[gs_i, :])\n",
    "        x_ticks_ax.set_xlim(start, end)\n",
    "        x_ticks_ax.xaxis.set_visible(True)\n",
    "        x_ticks_ax.spines['top'].set_visible(False)\n",
    "        x_ticks_ax.spines['left'].set_visible(False)\n",
    "        x_ticks_ax.spines['right'].set_visible(False)\n",
    "        x_ticks_ax.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "        # Hide y-axis and labels\n",
    "        x_ticks_ax.tick_params(left=False, labelleft=False)\n",
    "        x_ticks_ax.set_yticks([])\n",
    "        # Set a dummy plot for ticks visibility\n",
    "        x_ticks_ax.plot([start, end], [0, 0], color='white', alpha=0)  # Ensure the axis is plotted correctly\n",
    "    \n",
    "        # Determine tick step and format\n",
    "        tick_step = (end - start) // 5\n",
    "        if tick_step < 1:\n",
    "            tick_step = 1\n",
    "        tick_labels = []\n",
    "        tick_positions = []\n",
    "        for x in range(start, end + tick_step, tick_step):\n",
    "            tick_positions.append(x)\n",
    "            if (end - start) < 10000000:  # Less than 10 Mb range\n",
    "                tick_labels.append(f'{x / 10**6:.1f}'.rstrip('0').rstrip('.'))\n",
    "            else:\n",
    "                tick_labels.append(f'{x / 10**6:.0f}')\n",
    "        \n",
    "        x_ticks_ax.set_xticks(tick_positions)\n",
    "        x_ticks_ax.set_xticklabels(tick_labels)\n",
    "        \n",
    "        # Add a label to the x-axis\n",
    "        x_ticks_ax.set_xlabel('Chromosome position (Mb)')\n",
    "        \n",
    "        # Add extra ticks\n",
    "        minor_tick_step = tick_step // 5\n",
    "        if minor_tick_step > 0:\n",
    "            minor_ticks = []\n",
    "            for x in range(start, end, minor_tick_step):\n",
    "                if x not in tick_positions:\n",
    "                    minor_ticks.append(x)\n",
    "            x_ticks_ax.set_xticks(minor_ticks, minor=True)\n",
    "            x_ticks_ax.tick_params(axis='x', which='minor', bottom=True, top=False, labelbottom=False)\n",
    "\n",
    "\n",
    "\n",
    "    # Zoom the ideogram\n",
    "    if show_genes_allQ:\n",
    "        pyideogram.zoom(zoom_ax, all_chrom_ax)\n",
    "\n",
    "    if saveQ:\n",
    "        plt.savefig(f'figures/ideogram_{cell_line}.pdf', bbox_inches='tight', transparent=True, dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5948f0-729d-42ac-8f63-0a731a7da696",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### General plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09ee059f-6dad-4328-9ca2-aba5240474aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(cell_line, chr_number, data_type, chrmin=1, chrmax='max', aspect_ratio=5, ylimits=None, log_scale=False, smoothQ = False, sigma=5, standQ=False, saveQ=False):\n",
    "    \n",
    "    # Load data\n",
    "    if chrmax == 'max':\n",
    "        data = load_function(cell_line, chr_number, data_type, True)\n",
    "    else:\n",
    "        data = load_function(cell_line, chr_number, data_type, True)[chrmin:chrmax]\n",
    "\n",
    "    if smoothQ:\n",
    "        data = gaussian_filter1d(data, sigma=sigma, mode='constant', cval=np.nan)\n",
    "    \n",
    "    # Create figure with specified aspect ratio\n",
    "    plt.figure(figsize=(10, 10 / aspect_ratio))  # aspect_ratio controls height relative to width\n",
    "\n",
    "    if standQ:\n",
    "        data = zscore_with_nan(data)\n",
    "    \n",
    "    # Plot data\n",
    "    plt.plot(data)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel(title_map[data_type])\n",
    "    plt.title('')\n",
    "\n",
    "    # Set y-axis limits if provided\n",
    "    if ylimits is not None:\n",
    "        plt.ylim(ylimits)\n",
    "    \n",
    "    # Set y-axis to log scale if requested\n",
    "    if log_scale:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    plt.gca().set_yticks([])\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "\n",
    "    # Disable gridlines\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig(f'figures/plotsdetail_{data_type}.pdf', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694512f-ac73-4562-abe2-7f0daa22c36c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Correlations ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c569ada4-b66e-4b8f-b8ae-188036ce1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average correlations and export results to CSV\n",
    "def correlation_tests_to_csv(cell_lines, chr_numbers, data_types1, data_types2, output_file, chrmin=1, chrmax='max', smoothQ1=False, smoothQ2=False, sigma=50, standQ=True):\n",
    "    results = []\n",
    "\n",
    "    for cell_line in cell_lines:\n",
    "        for data_type1 in data_types1:\n",
    "            for data_type2 in data_types2:\n",
    "                # Initialize accumulators for correlations\n",
    "                pearson_corr_list = []\n",
    "                spearman_corr_list = []\n",
    "                kendall_corr_list = []\n",
    "\n",
    "                # Loop over the chromosomes\n",
    "                for chr_number in chr_numbers:\n",
    "                    # Load data for the first and second datasets\n",
    "                    if chrmax == 'max':\n",
    "                        data1 = load_function(cell_line, chr_number, data_type1, True)\n",
    "                        data2 = load_function(cell_line, chr_number, data_type2, True)\n",
    "                    else:\n",
    "                        data1 = load_function(cell_line, chr_number, data_type1, True)[chrmin:chrmax]\n",
    "                        data2 = load_function(cell_line, chr_number, data_type2, True)[chrmin:chrmax]\n",
    "\n",
    "                    # Check if any of the datasets are empty\n",
    "                    if data1.size == 0 or data2.size == 0:\n",
    "                        continue  # Skip further calculations for this chromosome\n",
    "                    \n",
    "                    # Apply Gaussian smoothing\n",
    "                    if smoothQ1:\n",
    "                        data1 = gaussian_filter1d(data1, sigma=sigma, mode='constant', cval=np.nan)\n",
    "                    if smoothQ2:\n",
    "                        data2 = gaussian_filter1d(data2, sigma=sigma, mode='constant', cval=np.nan)\n",
    "                    \n",
    "                    # Filter for valid (non-NaN, finite) data\n",
    "                    valid_mask = ~np.isnan(data1) & ~np.isnan(data2) & np.isfinite(data1) & np.isfinite(data2)\n",
    "                    data1, data2 = data1[valid_mask], data2[valid_mask]\n",
    "\n",
    "                    if standQ:\n",
    "                        data1 = zscore(data1)\n",
    "                        data2 = zscore(data2)\n",
    "\n",
    "                    if len(data1) > 0 and len(data2) > 0:\n",
    "                        # Compute Pearson's correlation\n",
    "                        pearson_corr, _ = pearsonr(data1, data2)\n",
    "                        pearson_corr_list.append(pearson_corr)\n",
    "                        \n",
    "                        # Compute Spearman's correlation\n",
    "                        spearman_corr, _ = spearmanr(data1, data2)\n",
    "                        spearman_corr_list.append(spearman_corr)\n",
    "                        \n",
    "                        # Compute Kendall's Tau correlation\n",
    "                        kendall_corr, _ = kendalltau(data1, data2)\n",
    "                        kendall_corr_list.append(kendall_corr)\n",
    "\n",
    "                # Compute the average correlations across chromosomes\n",
    "                if pearson_corr_list:\n",
    "                    avg_pearson_corr = np.mean(pearson_corr_list)\n",
    "                    avg_spearman_corr = np.mean(spearman_corr_list)\n",
    "                    avg_kendall_corr = np.mean(kendall_corr_list)\n",
    "                else:\n",
    "                    avg_pearson_corr = 'N/A'\n",
    "                    avg_spearman_corr = 'N/A'\n",
    "                    avg_kendall_corr = 'N/A'\n",
    "\n",
    "                # Store the averaged results\n",
    "                results.append({\n",
    "                    \"Cell line\": cell_line,\n",
    "                    \"Data type 1\": title_map[data_type1],\n",
    "                    \"Data type 2\": title_map[data_type2],\n",
    "                    \"Spearman\": round(avg_spearman_corr, 3) if avg_spearman_corr != 'N/A' else 'N/A',\n",
    "                    \"Kendall's Tau\": round(avg_kendall_corr, 3) if avg_kendall_corr != 'N/A' else 'N/A',\n",
    "                    \"Pearson\": round(avg_pearson_corr, 3) if avg_pearson_corr != 'N/A' else 'N/A'\n",
    "                })\n",
    "\n",
    "    # Convert results to DataFrame and write to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "433b8259-7cd2-48bd-a052-8527bd82bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmap(data, figsize=(12, 4), saveQ=False):\n",
    "\n",
    "    # Load the data from the CSV file\n",
    "    file_path = 'data/tables/correlations.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure the order of cell lines and data types as they appear in the CSV\n",
    "    df['Cell line'] = pd.Categorical(df['Cell line'], categories=df['Cell line'].unique(), ordered=True)\n",
    "    df['Data type 1'] = pd.Categorical(df['Data type 1'], categories=df['Data type 1'].unique(), ordered=True)\n",
    "    df['Data type 2'] = pd.Categorical(df['Data type 2'], categories=df['Data type 2'].unique(), ordered=True)\n",
    "\n",
    "    # Extract cell types from the DataFrame in the order they appear in the CSV\n",
    "    cell_types = df['Cell line'].cat.categories  # This will now preserve the order in the CSV\n",
    "\n",
    "    # Create a grid with enough space for all sub-heatmaps (3 heatmaps per cell type)\n",
    "    fig = plt.figure(figsize=(figsize[0], figsize[1] * len(cell_types)))  # Adjust height dynamically based on cell types\n",
    "    gs = gridspec.GridSpec(len(cell_types), 3, width_ratios=[1, 1, 1], wspace=0.05, hspace=0.1)\n",
    "\n",
    "    vmin, vmax = -1, 1  # Correlation values typically range from -1 to 1\n",
    "\n",
    "    for i, cell_type in enumerate(cell_types):\n",
    "        subset = df[df['Cell line'] == cell_type]\n",
    "        \n",
    "        # Create pivot tables for Pearson, Spearman, and Kendall's Tau, preserving the order of data types\n",
    "        heatmap_data_pearson = subset.pivot(index='Data type 1', columns='Data type 2', values='Pearson').reindex(index=subset['Data type 1'].cat.categories, columns=subset['Data type 2'].cat.categories)\n",
    "        heatmap_data_spearman = subset.pivot(index='Data type 1', columns='Data type 2', values='Spearman').reindex(index=subset['Data type 1'].cat.categories, columns=subset['Data type 2'].cat.categories)\n",
    "        heatmap_data_kendall = subset.pivot(index='Data type 1', columns='Data type 2', values=\"Kendall's Tau\").reindex(index=subset['Data type 1'].cat.categories, columns=subset['Data type 2'].cat.categories)\n",
    "        \n",
    "        # Ensure that the diagonal is 1\n",
    "        for heatmap_data in [heatmap_data_pearson, heatmap_data_spearman, heatmap_data_kendall]:\n",
    "            for col in heatmap_data.columns:\n",
    "                if col in heatmap_data.index:\n",
    "                    heatmap_data.loc[col, col] = 1\n",
    "        \n",
    "        # Plot Pearson, Spearman, and Kendall's Tau in a row for each cell type\n",
    "        ax0 = fig.add_subplot(gs[i, 0])\n",
    "        sns.heatmap(heatmap_data_pearson, annot=True, annot_kws={\"rotation\": 90}, cmap=\"coolwarm\", cbar=False, vmin=vmin, vmax=vmax, ax=ax0)\n",
    "        ax0.set_xlabel('')\n",
    "        if i < len(cell_types) - 1:\n",
    "            plt.xticks(ticks=[])  # Remove x-ticks on all rows but the last\n",
    "        if i == 0:\n",
    "            ax0.set_title('Pearson')\n",
    "        ax0.set_ylabel(cell_type)  # Set the cell line name as the y-label only, preserving the order in the CSV\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[i, 1])\n",
    "        sns.heatmap(heatmap_data_spearman, annot=True, annot_kws={\"rotation\": 90}, cmap=\"coolwarm\", cbar=False, vmin=vmin, vmax=vmax, ax=ax1)\n",
    "        ax1.set_xlabel('')\n",
    "        if i < len(cell_types) - 1:\n",
    "            plt.xticks(ticks=[])  # Remove x-ticks on all rows but the last\n",
    "        ax1.set_yticks([])  # Remove y-tick labels for columns other than the first\n",
    "        if i == 0:\n",
    "            ax1.set_title('Spearman')\n",
    "        ax1.set_ylabel('')\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[i, 2])\n",
    "        sns.heatmap(heatmap_data_kendall, annot=True, annot_kws={\"rotation\": 90}, cmap=\"coolwarm\", cbar=False, vmin=vmin, vmax=vmax, ax=ax2)\n",
    "        if i < len(cell_types) - 1:\n",
    "            plt.xticks(ticks=[])  # Remove x-ticks except on last row\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.set_yticks([])  # Remove y-ticks for columns other than the first\n",
    "        if i == 0:\n",
    "            ax2.set_title(\"Kendall's Tau\")\n",
    "        ax2.set_ylabel('')\n",
    "\n",
    "    # Add a single color bar for the whole figure, matching the height of the heatmaps\n",
    "    # Add a single color bar for the whole figure, positioned at the top with vertical ticks\n",
    "    cbar_ax = fig.add_axes([0.05, 0.95, 0.85, 0.02])  # Adjust the position [left, bottom, width, height]\n",
    "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\n",
    "    \n",
    "    # Move the ticks to the top of the color bar\n",
    "    cbar.ax.xaxis.set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels to be vertical\n",
    "    cbar.ax.xaxis.set_tick_params(rotation=90)\n",
    "    cbar.ax.invert_xaxis()\n",
    "\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(left=0.05, right=0.9, top=0.9, bottom=0.05, wspace=0.05, hspace=0.2)\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/correlations.pdf', bbox_inches='tight', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9c4ea-dd32-4bb9-b537-29e78622c135",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fragile sites plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d146ee8-c6e5-4b77-a960-db0d643041f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate continuous segment lengths where values > threshold\n",
    "def find_continuous_segments(data, threshold):\n",
    "    lengths = []\n",
    "    current_length = 0\n",
    "    for value in data:\n",
    "        if value > threshold:\n",
    "            current_length += 1\n",
    "        else:\n",
    "            if current_length > 0:\n",
    "                lengths.append(current_length)\n",
    "            current_length = 0\n",
    "    if current_length > 0:  # Catch the last segment if it ends with a continuous section\n",
    "        lengths.append(current_length)\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7d5a54e-8536-424e-b04f-1f71e15ba642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragiles_plot(cell_line, common_fragile_sites, rare_fragile_sites, threshold, saveQ=False):\n",
    "\n",
    "    # Combine all fragile sites\n",
    "    all_fragile_sites = common_fragile_sites + rare_fragile_sites\n",
    "    \n",
    "    # Initialize lists for data\n",
    "    errors_fragile = []\n",
    "    labels_fragile = []\n",
    "    fragile_site_lengths = []  # Total lengths of fragile sites\n",
    "    fragile_site_misfit_lengths = []  # Misfit lengths in fragile sites\n",
    "    \n",
    "    # Loop over all fragile sites to load data and calculate segments\n",
    "    for site_label, chrom in all_fragile_sites:\n",
    "        positions = load_function_pos(chrom, \"fragile_sites\", cell_line=None, site_letter=site_label[-1], base='A')\n",
    "        data = load_function(cell_line, chrom, \"error\")\n",
    "        errors_fragile.append(data[positions])\n",
    "        labels_fragile.append(site_label)\n",
    "        \n",
    "        # Calculate the total length and misfit length of the fragile site\n",
    "        total_length = len(data[positions])\n",
    "        misfit_length = np.sum(np.array(data[positions]) > threshold) \n",
    "        fragile_site_lengths.append(total_length)\n",
    "        fragile_site_misfit_lengths.append(misfit_length)\n",
    "    \n",
    "    # Calculate continuous segment lengths for each sublist in errors_fragile\n",
    "    continuous_lengths = [find_continuous_segments(sublist, threshold) for sublist in errors_fragile]\n",
    "    \n",
    "    # Create a figure with two stacked subplots (reversed order)\n",
    "    fig, (ax2, ax1) = plt.subplots(2, 1, figsize=(8, 5), sharex=True, gridspec_kw={'height_ratios': [1, .8]})\n",
    "    \n",
    "    # Define a spacing factor between common and rare fragile sites\n",
    "    spacing = 2\n",
    "    bar_width = 0.5  # Width of the bars\n",
    "    \n",
    "    # Adjusted positions for alignment\n",
    "    index_common = np.arange(1, len(common_fragile_sites) + 1)\n",
    "    index_rare = np.arange(len(common_fragile_sites) + spacing, len(common_fragile_sites) + spacing + len(rare_fragile_sites))\n",
    "    index = np.concatenate([index_common, index_rare])\n",
    "    \n",
    "    # First plot (top): Continuous misfit regions (boxplot)\n",
    "    common_box = ax2.boxplot(continuous_lengths[:len(common_fragile_sites)], \n",
    "                             positions=index_common,\n",
    "                             widths=bar_width, patch_artist=True, boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                             medianprops=dict(color='red'), whiskerprops=dict(color='black'))\n",
    "    \n",
    "    rare_box = ax2.boxplot(continuous_lengths[len(common_fragile_sites):], \n",
    "                           positions=index_rare,\n",
    "                           widths=bar_width, patch_artist=True, boxprops=dict(facecolor='lightgreen', color='black'),\n",
    "                           medianprops=dict(color='red'), whiskerprops=dict(color='black'))\n",
    "    \n",
    "    # Dashed line separating common and rare fragile sites in the top plot\n",
    "    ax2.axvline(len(common_fragile_sites) + spacing / 2, color='gray', linestyle='--')\n",
    "\n",
    "    # Set section titles for ax2 (top plot)\n",
    "    ax2.text(len(common_fragile_sites) / 2 + 0.5, ax2.get_ylim()[1] * 1.04, 'Common fragile sites', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    ax2.text(len(common_fragile_sites) + spacing - 0.5 + len(rare_fragile_sites) / 2, ax2.get_ylim()[1] * 1.04, \n",
    "             'Rare fragile sites', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Set labels and title for the top plot\n",
    "    ax2.set_ylabel('Continuous misfit regions (kb)', fontsize=10)\n",
    "    \n",
    "    # Remove x-ticks from the top plot (boxplot)\n",
    "    ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    \n",
    "    # Second plot (bottom): Total fragile site lengths and misfit proportions (bar plot)\n",
    "    fragile_site_bars_common = ax1.bar(index_common, np.array(fragile_site_lengths[:len(common_fragile_sites)]) / 1000, \n",
    "                                       bar_width, label='Common FS', color='lightblue')\n",
    "    fragile_site_bars_rare = ax1.bar(index_rare, np.array(fragile_site_lengths[len(common_fragile_sites):]) / 1000, \n",
    "                                     bar_width, label='Rare FS', color='lightgreen')\n",
    "    \n",
    "    fragile_site_misfit_bars_common = ax1.bar(index_common, np.array(fragile_site_misfit_lengths[:len(common_fragile_sites)]) / 1000, \n",
    "                                              bar_width, color='firebrick', label='Misfit fraction')\n",
    "    fragile_site_misfit_bars_rare = ax1.bar(index_rare, np.array(fragile_site_misfit_lengths[len(common_fragile_sites):]) / 1000, \n",
    "                                            bar_width, color='firebrick')\n",
    "    \n",
    "    # Dashed line separating common and rare fragile sites in the bottom plot\n",
    "    ax1.axvline(len(common_fragile_sites) + spacing / 2, color='gray', linestyle='--')\n",
    "    \n",
    "    # Set labels and title for the second plot (in Mb)\n",
    "    ax1.set_ylabel('Length (Mb)', fontsize=10)\n",
    "    \n",
    "    # Set x-ticks and labels for both plots (bottom plot only)\n",
    "    ax1.set_xticks(index)\n",
    "    ax1.set_xticklabels(labels_fragile, rotation=45, ha='right')\n",
    "    \n",
    "    # Add legend to the bottom plot in the upper right corner\n",
    "    ax1.legend(loc='upper right', fontsize=9)\n",
    "    \n",
    "    # Increase space between the outermost boxplots and the frame axes for both plots\n",
    "    ax1.set_xlim(0, len(common_fragile_sites) + len(rare_fragile_sites) + spacing)\n",
    "    \n",
    "    # Remove spacing between the subplots and ensure axes labels don't overlap\n",
    "    plt.subplots_adjust(hspace=1)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout(pad=-0.1)\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/fragile_box.pdf', bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea459e-7fa7-42de-ab1d-de194ac3627b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Genes plots ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22ffdea4-387c-43f4-b6d6-125b831338ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genes_plot(cell_line, genes, threshold, fragile_sites, saveQ=False):\n",
    "    \n",
    "    # Initialize lists for data\n",
    "    errors_genes = []\n",
    "    labels_genes = []\n",
    "    gene_lengths = []  # Total lengths of genes\n",
    "    gene_misfit_fractions = []  # Misfit fractions in genes\n",
    "    \n",
    "    # Loop over all genes to load data and calculate segments\n",
    "    for i, (gene_name, chrom) in enumerate(genes):\n",
    "        # Load positions of the gene\n",
    "        positions = load_function_pos(chrom, \"gene\", gene_name=gene_name)\n",
    "        \n",
    "        # Load error data for the chromosome\n",
    "        data = load_function(cell_line, chrom, \"error\")\n",
    "        \n",
    "        # Extract the data for the specific gene positions\n",
    "        gene_data = data[positions]\n",
    "        \n",
    "        # Store the gene data and label\n",
    "        errors_genes.append(gene_data)\n",
    "        \n",
    "        # Combine gene name with fragile site in label\n",
    "        labels_genes.append(f\"{gene_name}\\n{fragile_sites[i]}\")\n",
    "        \n",
    "        # Calculate the total length and misfit fraction of the gene\n",
    "        total_length = len(gene_data)\n",
    "        misfit_length = np.sum(np.array(gene_data) > threshold)  # Count misfit segments based on threshold\n",
    "        misfit_fraction = misfit_length / total_length if total_length > 0 else 0  # Calculate fraction\n",
    "        gene_lengths.append(total_length)\n",
    "        gene_misfit_fractions.append(misfit_fraction)\n",
    "    \n",
    "    # Sort data by gene size (descending order)\n",
    "    sorted_indices = np.argsort(gene_lengths)[::-1]\n",
    "    gene_lengths = np.array(gene_lengths)[sorted_indices]\n",
    "    gene_misfit_fractions = np.array(gene_misfit_fractions)[sorted_indices]\n",
    "    labels_genes = np.array(labels_genes)[sorted_indices]\n",
    "    \n",
    "    # Create a figure for bar plots\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "    # Convert lengths to Mb by dividing by 1000\n",
    "    gene_lengths_mb = gene_lengths / 1000\n",
    "    gene_misfit_lengths_mb = [length * fraction / 1000 for length, fraction in zip(gene_lengths, gene_misfit_fractions)]\n",
    "\n",
    "    # Define the width of the bars and spacing\n",
    "    bar_width = 0.4\n",
    "    index = np.arange(len(genes))\n",
    "    \n",
    "    # Plot the total gene lengths in Mb\n",
    "    gene_bars = ax1.bar(index, gene_lengths_mb, bar_width, label='Gene', color='wheat')\n",
    "    \n",
    "    # Plot the misfit fractions in Mb on top of the total gene lengths\n",
    "    misfit_bars = ax1.bar(index, gene_misfit_lengths_mb, \n",
    "                          bar_width, color='firebrick', label='Misfit fraction', bottom=0)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax1.set_ylabel('Length (Mb)', fontsize=12)\n",
    "    ax1.set_title('Large genes', fontsize=14)\n",
    "\n",
    "    # Add gene labels to x-axis\n",
    "    ax1.set_xticks(index)\n",
    "    ax1.set_xticklabels(labels_genes, rotation=45, ha='center', fontsize=10)\n",
    "\n",
    "    # Add legend\n",
    "    ax1.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/gene_bars.pdf', bbox_inches='tight', transparent=True)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36681f6-6cfb-496d-8214-e186e24850ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_detector_error():\n",
    "\n",
    "    # Example usage\n",
    "    cell_line = \"H1\"\n",
    "    chr_numbers = range(1,23)\n",
    "    data_type = \"error\"\n",
    "    threshold = 10**2.8\n",
    "    nmax = 10\n",
    "    \n",
    "    positions = []\n",
    "    for chr_number in chr_numbers:\n",
    "        \n",
    "        error = load_function(cell_line, chr_number, data_type)\n",
    "        local_max0 = argrelextrema(error, np.greater)[0]\n",
    "        local_max = [value for value in local_max0 if error[value] > threshold]\n",
    "        \n",
    "        local_max_list = [np.array(range(max(0,maxi - nmax), min(chr_lengths[chr_number-1],maxi + nmax)+1)) for maxi in local_max]\n",
    "        \n",
    "        positions.append([item for sublist in local_max_list for item in sublist])\n",
    "    \n",
    "    # Input BigBed file and output directory\n",
    "    bigbed_path = r'data/genome_regions/genes/gencodeV46.bb'\n",
    "    output_dir = r'data/genome_regions/genes/'\n",
    "    \n",
    "    # Open the BigBed file using pybigtools\n",
    "    bb = pybigtools.open(bigbed_path)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # List of chromosomes as strings (1-22)\n",
    "    chromosomes = [str(i) for i in range(1, 23)]\n",
    "    \n",
    "    # Loop over each chromosome\n",
    "    for i, chrom in enumerate(chromosomes):\n",
    "    \n",
    "        gene_names = []\n",
    "        gene_lengths = []\n",
    "        \n",
    "        # Initialize a list representing the chromosome at 1kb resolution, with each position set to 0\n",
    "        chrom_data = [0] * chr_lengths[i]\n",
    "        \n",
    "        # List to store exact coding positions (in kb)\n",
    "        exact_positions = []\n",
    "        \n",
    "        # Query all records for the chromosome\n",
    "        for record in bb.records(f\"chr{chrom}\"):\n",
    "            chrom_start = record[0]\n",
    "            chrom_end = record[1]\n",
    "            fields = record[2:]  # Additional fields, including transcript class\n",
    "            \n",
    "            # Assuming transcriptClass is in a specific position\n",
    "            transcript_class = fields[17]\n",
    "    \n",
    "            # Only process coding transcripts\n",
    "            if transcript_class == 'coding':\n",
    "                rangepos = range(chrom_start // 1000, min(chrom_end // 1000 + 1, chr_lengths[i]))\n",
    "                \n",
    "                # Mark positions as coding (1) for the corresponding 1kb intervals\n",
    "                for pos in rangepos:\n",
    "                    chrom_data[pos] = 1\n",
    "                \n",
    "                # Store exact positions for coding intervals\n",
    "                for pos in rangepos:\n",
    "                    exact_positions.append(pos)\n",
    "    \n",
    "                if set(rangepos) & set(positions[i]):\n",
    "                    gene_name = fields[14]\n",
    "                    gene_length = chrom_end//1000-chrom_start//1000\n",
    "                    gene_names.append(gene_name)\n",
    "                    gene_lengths.append(gene_length)\n",
    "    \n",
    "                        \n",
    "        genes_with_lengths = list(zip(gene_names, gene_lengths))\n",
    "        genes_with_lengths.sort(key=lambda x: x[1], reverse=True)\n",
    "        sorted_gene_names = [gene for gene, length in genes_with_lengths]\n",
    "        sorted_gene_names = list(dict.fromkeys(sorted_gene_names))\n",
    "        \n",
    "        # Save the sorted and deduplicated gene names to a text file\n",
    "        np.savetxt(f\"data/genome_regions/genes/gene_error_chr[{i+1}].txt\", sorted_gene_names, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854c27c-466e-4d84-96fe-aea80d2a425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_detector_fragile_sites(chr_number):\n",
    "    # Load gene names from the text file for the given chromosome\n",
    "    gene_file = f\"data/genome_regions/genes/gene_error_chr[{chr_number}].txt\"\n",
    "    \n",
    "    if not os.path.exists(gene_file):\n",
    "        print(f\"No gene file found for chromosome {chr_number}.\")\n",
    "        return [], []\n",
    "    \n",
    "    # Load only the first 10 gene names\n",
    "    gene_names = np.loadtxt(gene_file, dtype=str, ndmin=1)[:12]\n",
    "\n",
    "    # Load BigBed file for gene data\n",
    "    bigbed_path = r'data/genome_regions/genes/gencodeV46.bb'\n",
    "    bb = pybigtools.open(bigbed_path)\n",
    "    \n",
    "    # Initialize a dictionary to store fragile site positions by letter\n",
    "    fragile_sites = {}\n",
    "    for site_letter in string.ascii_uppercase:  # Iterate over all capital letters A-Z\n",
    "        site_file = f\"data/genome_regions/fragile_sites/positions_fragile_site_{chr_number}{site_letter}.txt\"\n",
    "        if os.path.exists(site_file):\n",
    "            site_positions = np.loadtxt(site_file, dtype=int)\n",
    "            fragile_sites[site_letter] = site_positions\n",
    "    \n",
    "    # Initialize lists to store matching genes and respective fragile sites\n",
    "    matching_genes = []\n",
    "    matching_fragile_sites = []\n",
    "    \n",
    "    # Loop over each gene name (only first 10)\n",
    "    for gene_name in gene_names:\n",
    "        # Query all records for the specified chromosome to find the gene's position\n",
    "        gene_found = False\n",
    "        for record in bb.records(f\"chr{chr_number}\"):\n",
    "            fields = record[2:]  # Additional fields, including gene information\n",
    "            if fields[14] == gene_name:  # Match the gene name\n",
    "                chrom_start = record[0] // 1000  # Start position in kb\n",
    "                chrom_end = record[1] // 1000    # End position in kb\n",
    "                gene_found = True\n",
    "                break  # Stop once the gene is found\n",
    "        \n",
    "        if not gene_found:\n",
    "            continue\n",
    "        \n",
    "        # Check if the gene overlaps with any fragile sites\n",
    "        for site_letter, site_positions in fragile_sites.items():\n",
    "            for fragile_site_pos in site_positions:\n",
    "                if fragile_site_pos >= chrom_start and fragile_site_pos <= chrom_end:\n",
    "                    matching_genes.append(gene_name)\n",
    "                    matching_fragile_sites.append(f\"Fragile site {chr_number}{site_letter} at {fragile_site_pos} kb\")\n",
    "                    break  # Stop checking once the gene overlaps with a fragile site\n",
    "    \n",
    "    # Return the sublist of genes and their respective fragile sites\n",
    "    return matching_genes, matching_fragile_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a201d-7cb9-42d6-bfcb-c705ceadaae3",
   "metadata": {},
   "source": [
    "#### Pie and bar charts ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3de0e1b4-5535-4e27-b1a6-13d1bbf461b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pie_chart(data_lists, labels, ax, title=''):\n",
    "    if len(data_lists) != len(labels):\n",
    "        raise ValueError(\"The number of data lists and labels must be the same.\")\n",
    "    \n",
    "    # Count the number of elements in each sublist\n",
    "    sizes = [len(data_list) for data_list in data_lists]\n",
    "    \n",
    "    # Automatically generate a color palette based on the number of categories\n",
    "    num_categories = len(data_lists)\n",
    "    colors = sns.color_palette('flare', max(num_categories + 1, 3))[1:num_categories + 1]  # Ensure enough distinct colors\n",
    "    \n",
    "    # Create the pie chart on the provided axis\n",
    "    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "    \n",
    "    # Set the color of the percentages to white\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "    \n",
    "    # Set equal aspect ratio to ensure the pie is drawn as a circle\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    # Set a title for the pie chart\n",
    "    ax.set_title(title, fontsize=11)\n",
    "\n",
    "\n",
    "def plot_four_pie_charts(cell_line, chr_numbers, error_threshold, time_threshold, saveQ=False):\n",
    "    # Set up the figure for subplots (4 pie charts)\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    ### Initialize data lists for all pie charts ###\n",
    "    late_data, early_data = [], []\n",
    "    coding_data, noncoding_data = [], []\n",
    "    at_data, gc_data = [], []\n",
    "    telomere_data, centromere_data, cfs_data, rfs_data, other_data = [], [], [], [], []\n",
    "\n",
    "    common_sites = [\n",
    "        \"1A\", \"1B\", \"1C\", \"1D\", \"2A\", \"2B\", \"2C\", \"3B\", \"3C\", \"3D\", \"6E\", \"6F\", \n",
    "        \"7C\", \"7G\", \"7H\", \"7Q\", \"9A\", \"9B\", \"9C\", \"9D\", \"10A\", \"10B\", \"10C\", \n",
    "        \"11A\", \"11B\", \"12A\", \"12B\", \"12C\", \"16B\", \"16C\", \"16D\", \"17A\", \"17B\", \n",
    "        \"18B\", \"18C\", \"19A\", \"19B\", \"20A\", \"21A\"\n",
    "    ]\n",
    "\n",
    "    rare_sites = [\n",
    "        \"1E\", \"1F\", \"1G\", \"1H\", \"4A\", \"4B\", \"5A\", \"5B\", \"5C\", \"8A\", \"8B\", \"8C\", \n",
    "        \"13A\", \"13B\", \"13C\", \"14A\", \"14B\", \"15A\", \"15B\", \"16E\", \"17C\", \"18A\",\n",
    "        \"20B\", \"21B\", \"22A\", \"22B\"\n",
    "    ]\n",
    "\n",
    "    ### Loop through all chromosomes and collect data for all charts ###\n",
    "    for chr_number in chr_numbers:\n",
    "        # Load the data for the current chromosome\n",
    "        error = load_function(cell_line, chr_number, \"error\")\n",
    "        time = load_function(cell_line, chr_number, \"time_data\")\n",
    "\n",
    "        # Handle replication timing (Late vs Early)\n",
    "        late_condition = (time > time_threshold) & (error > error_threshold)\n",
    "        early_condition = (time <= time_threshold) & (error > error_threshold)\n",
    "        late_data.extend(error[late_condition])\n",
    "        early_data.extend(error[early_condition])\n",
    "\n",
    "        # Handle coding vs non-coding regions\n",
    "        positions_coding = load_function_pos(chr_number, \"coding\")\n",
    "        positions_noncoding = list(set(range(len(error))) - set(positions_coding))\n",
    "\n",
    "        error_coding = error[positions_coding]\n",
    "        error_noncoding = error[positions_noncoding]\n",
    "        coding_data.extend([i for i in error_coding if i > error_threshold])\n",
    "        noncoding_data.extend([i for i in error_noncoding if i > error_threshold])\n",
    "\n",
    "        # Handle base composition (AT vs GC)\n",
    "        positions_A = load_function_pos(chr_number, \"bases\", base='A')\n",
    "        positions_T = load_function_pos(chr_number, \"bases\", base='T')\n",
    "        positions_G = load_function_pos(chr_number, \"bases\", base='G')\n",
    "        positions_C = load_function_pos(chr_number, \"bases\", base='C')\n",
    "\n",
    "        positions_AT = np.concatenate((positions_A, positions_T))\n",
    "        positions_GC = np.concatenate((positions_G, positions_C))\n",
    "\n",
    "        error_AT = error[positions_AT]\n",
    "        error_GC = error[positions_GC]\n",
    "        at_data.extend([i for i in error_AT if i > error_threshold])\n",
    "        gc_data.extend([i for i in error_GC if i > error_threshold])\n",
    "\n",
    "        # Handle genomic regions (Telomeres, Centromeres, CFS, RFS, Others)\n",
    "        positions_telomeres = load_function_pos(chr_number, \"telomeres\")\n",
    "        positions_centromeres = load_function_pos(chr_number, \"centromeres\")\n",
    "        error_telomeres = error[positions_telomeres]\n",
    "        error_centromeres = error[positions_centromeres]\n",
    "\n",
    "        common_sites_chr = [site for site in common_sites if re.match(f\"^{chr_number}[A-Z]$\", site)]\n",
    "        rare_sites_chr = [site for site in rare_sites if re.match(f\"^{chr_number}[A-Z]$\", site)]\n",
    "\n",
    "        error_common_sites = []\n",
    "        error_rare_sites = []\n",
    "        \n",
    "        # Ensure that positions are within bounds\n",
    "        for site in common_sites_chr:\n",
    "            positions_common_sites = load_function_pos(chr_number, \"fragile_sites\", site_letter=site[-1])\n",
    "            positions_common_sites = np.intersect1d(positions_common_sites, np.arange(len(error)))  # Bounds check\n",
    "            error_common_sites.extend(error[positions_common_sites])\n",
    "\n",
    "        for site in rare_sites_chr:\n",
    "            positions_rare_sites = load_function_pos(chr_number, \"fragile_sites\", site_letter=site[-1])\n",
    "            positions_rare_sites = np.intersect1d(positions_rare_sites, np.arange(len(error)))  # Bounds check\n",
    "            error_rare_sites.extend(error[positions_rare_sites])\n",
    "\n",
    "        # Define other regions as everything outside telomeres, centromeres, and fragile sites\n",
    "        positions_fragile = np.concatenate((positions_telomeres, positions_centromeres, positions_common_sites, positions_rare_sites))\n",
    "        positions_other = list(set(range(len(error))) - set(positions_fragile))\n",
    "        error_other = error[positions_other]\n",
    "\n",
    "        # Append data to corresponding lists\n",
    "        telomere_data.extend([i for i in error_telomeres if i > error_threshold])\n",
    "        centromere_data.extend([i for i in error_centromeres if i > error_threshold])\n",
    "        cfs_data.extend([i for i in error_common_sites if i > error_threshold])\n",
    "        rfs_data.extend([i for i in error_rare_sites if i > error_threshold])\n",
    "        other_data.extend([i for i in error_other if i > error_threshold])\n",
    "\n",
    "    ### Generate Pie Charts ###\n",
    "    # Pie chart 1: Replication timing (Late vs Early)\n",
    "    data_lists_1 = [late_data, early_data]\n",
    "    labels_1 = ['Late', 'Early']\n",
    "    generate_pie_chart(data_lists_1, labels_1, axs[0], title='Replication timing')\n",
    "\n",
    "    # Pie chart 2: Coding vs Non-coding regions\n",
    "    data_lists_2 = [noncoding_data, coding_data]\n",
    "    labels_2 = ['Non-coding','Coding']\n",
    "    generate_pie_chart(data_lists_2, labels_2, axs[1], title='Coding regions')\n",
    "\n",
    "    # Pie chart 3: Base composition (AT vs GC)\n",
    "    data_lists_3 = [at_data, gc_data]\n",
    "    labels_3 = ['AT', 'GC']\n",
    "    generate_pie_chart(data_lists_3, labels_3, axs[2], title='Base composition')\n",
    "\n",
    "    # Pie chart 4: Genomic regions (Telomeres, Centromeres, CFS, RFS, Others)\n",
    "    data_lists_4 = [rfs_data, cfs_data, other_data, centromere_data, telomere_data]\n",
    "    labels_4 = ['RFS','CFS','Other','Centromeres','Telomeres']\n",
    "    generate_pie_chart(data_lists_4, labels_4, axs[3], title='Genomic regions')\n",
    "\n",
    "    # Save plot\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/piecharts.pdf', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515bc3c-8836-4433-b54c-95a4a8cbd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplots():\n",
    "    \n",
    "    error_threshold = 10**2\n",
    "        \n",
    "    ### Loop through all chromosomes and collect data for all charts ###\n",
    "    \n",
    "    cell_line = \"H1\"\n",
    "    chr_numbers = range(1,23)\n",
    "    #error_threshold = 1\n",
    "    time_threshold = 250\n",
    "    \n",
    "    late_data = []\n",
    "    early_data = []\n",
    "    coding_data = []\n",
    "    noncoding_data = []\n",
    "    at_data = []\n",
    "    gc_data = []\n",
    "    telomere_data, centromere_data, cfs_data, rfs_data, other_data = [], [], [], [], []\n",
    "    \n",
    "    err_early_data, err_late_data, err_coding_data, err_noncoding_data, err_at_data, err_gc_data, err_centromeres_data, err_telomeres_data, err_cfs_data, err_rfs_data, err_other_data = [], [], [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    common_sites = [\"1A\", \"1B\", \"1C\", \"1D\", \"2A\", \"2B\", \"2C\", \"3B\", \"3C\", \"3D\", \"6E\", \"6F\", \n",
    "        \"7C\", \"7G\", \"7H\", \"7Q\", \"9A\", \"9B\", \"9C\", \"9D\", \"10A\", \"10B\", \"10C\", \n",
    "        \"11A\", \"11B\", \"12A\", \"12B\", \"12C\", \"16B\", \"16C\", \"16D\", \"17A\", \"17B\", \n",
    "        \"18B\", \"18C\", \"19A\", \"19B\", \"20A\", \"21A\"]\n",
    "    rare_sites = [\"1E\", \"1F\", \"1G\", \"1H\", \"4A\", \"4B\", \"5A\", \"5B\", \"5C\", \"8A\", \"8B\", \"8C\", \n",
    "        \"13A\", \"13B\", \"13C\", \"14A\", \"14B\", \"15A\", \"15B\", \"16E\", \"17C\", \"18A\",\n",
    "        \"20B\", \"21B\", \"22A\", \"22B\"]\n",
    "    \n",
    "    for chr_number in chr_numbers:\n",
    "        # Load the data for the current chromosome\n",
    "        error = load_function(cell_line, chr_number, \"error\")\n",
    "        time = load_function(cell_line, chr_number, \"time_data\")\n",
    "    \n",
    "        # Handle replication timing (Late vs Early)\n",
    "        late_data.append(len(error[(time > time_threshold) & (error > error_threshold)])/len(error[(time > time_threshold)]))\n",
    "        early_data.append(len(error[(time <= time_threshold) & (error > error_threshold)])/len(error[(time <= time_threshold)]))\n",
    "        err_late_data.extend(error[(time > time_threshold)])\n",
    "        err_early_data.extend(error[(time <= time_threshold)])\n",
    "    \n",
    "        # Handle coding vs non-coding regions\n",
    "        positions_coding = load_function_pos(chr_number, \"coding\")\n",
    "        positions_noncoding = list(set(range(len(error))) - set(positions_coding))\n",
    "        error_coding = error[positions_coding]\n",
    "        error_noncoding = error[positions_noncoding]\n",
    "        coding_data.append(len(error_coding[error_coding > error_threshold])/len(error_coding))\n",
    "        noncoding_data.append(len(error_noncoding[error_noncoding > error_threshold])/len(error_noncoding))\n",
    "        err_coding_data.extend(error_coding)\n",
    "        err_noncoding_data.extend(error_noncoding)\n",
    "    \n",
    "        # Handle base composition (AT vs GC)\n",
    "        positions_A = load_function_pos(chr_number, \"bases\", base='A')\n",
    "        positions_T = load_function_pos(chr_number, \"bases\", base='T')\n",
    "        positions_G = load_function_pos(chr_number, \"bases\", base='G')\n",
    "        positions_C = load_function_pos(chr_number, \"bases\", base='C')\n",
    "        positions_AT = np.concatenate((positions_A, positions_T))\n",
    "        positions_GC = np.concatenate((positions_G, positions_C))\n",
    "        error_at = error[positions_AT]\n",
    "        error_gc = error[positions_GC]\n",
    "        at_data.append(len(error_at[error_at > error_threshold])/len(error_at))\n",
    "        gc_data.append(len(error_gc[error_gc > error_threshold])/len(error_gc))\n",
    "        err_at_data.extend(error_at)\n",
    "        err_gc_data.extend(error_gc)\n",
    "    \n",
    "    \n",
    "        # Handle genomic regions (Telomeres, Centromeres, CFS, RFS, Others)\n",
    "        positions_telomeres = load_function_pos(chr_number, \"telomeres\")\n",
    "        positions_centromeres = load_function_pos(chr_number, \"centromeres\")\n",
    "        error_telomeres = error[positions_telomeres]\n",
    "        error_centromeres = error[positions_centromeres]\n",
    "        common_sites_chr = [site for site in common_sites if re.match(f\"^{chr_number}[A-Z]$\", site)]\n",
    "        rare_sites_chr = [site for site in rare_sites if re.match(f\"^{chr_number}[A-Z]$\", site)]\n",
    "        error_common_sites = []\n",
    "        error_rare_sites = []\n",
    "        # Ensure that positions are within bounds\n",
    "        for site in common_sites_chr:\n",
    "            positions_common_sites = load_function_pos(chr_number, \"fragile_sites\", site_letter=site[-1])\n",
    "            positions_common_sites = np.intersect1d(positions_common_sites, np.arange(len(error)))  # Bounds check\n",
    "            error_common_sites.extend(error[positions_common_sites])\n",
    "        for site in rare_sites_chr:\n",
    "            positions_rare_sites = load_function_pos(chr_number, \"fragile_sites\", site_letter=site[-1])\n",
    "            positions_rare_sites = np.intersect1d(positions_rare_sites, np.arange(len(error)))  # Bounds check\n",
    "            error_rare_sites.extend(error[positions_rare_sites])\n",
    "        # Define other regions as everything outside telomeres, centromeres, and fragile sites\n",
    "        positions_fragile = np.concatenate((positions_telomeres, positions_centromeres, positions_common_sites, positions_rare_sites))\n",
    "        positions_other = list(set(range(len(error))) - set(positions_fragile))\n",
    "        error_other = error[positions_other]\n",
    "        telomere_data.append(len(error_telomeres[error_telomeres > error_threshold])/len(error_telomeres))\n",
    "        centromere_data.append(len(positions_centromeres[positions_centromeres > error_threshold])/len(positions_centromeres))\n",
    "        if len(error_common_sites) != 0:\n",
    "            cfs_data.append(len(np.array(error_common_sites)[np.array(error_common_sites) > error_threshold])/len(error_common_sites))\n",
    "        if len(error_rare_sites) != 0:\n",
    "            rfs_data.append(len(np.array(error_rare_sites)[np.array(error_rare_sites) > error_threshold])/len(error_rare_sites))\n",
    "        other_data.append(len(error_other[error_other > error_threshold])/len(error_other))\n",
    "        err_centromeres_data.extend(error_centromeres)\n",
    "        err_telomeres_data.extend(error_telomeres)\n",
    "        err_cfs_data.extend(error_common_sites)\n",
    "        err_rfs_data.extend(error_rare_sites)\n",
    "        err_other_data.extend(error_other)\n",
    "    \n",
    "    data_total = [early_data, late_data,\n",
    "    coding_data, noncoding_data,\n",
    "    at_data, gc_data,\n",
    "    telomere_data, cfs_data, rfs_data, other_data]\n",
    "    \n",
    "    mean_data_total = [np.mean(dat) for dat in data_total]\n",
    "    labels = [\"Early\", \"Late\", \"Coding\", \"Non-coding\", \"AT\", \"GC\", \"Telomeres\", \"CFS\", \"RFS\", \"Other\"]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, mean_data_total)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.ylabel(\"Percentage\")\n",
    "    plt.title(\"Percentage Bar Plot by Category\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    saveQ=True\n",
    "    if saveQ:\n",
    "        plt.savefig('figures/barplots_err.pdf', bbox_inches='tight', transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "    labels = [\"Early\", \"Late\"]\n",
    "    plot_relative_kdes([np.array(err_early_data),np.array(err_late_data)], labels, log_scale=True, x_min=10**-8, x_max=10**6,\n",
    "                   plot_title=\"\", x_title=\"error\", normalize = False,\n",
    "                   bw_adjust=1, saveQ=True)\n",
    "    labels = [\"Coding\", \"Non-coding\"]\n",
    "    plot_relative_kdes([np.array(err_coding_data),np.array(err_noncoding_data)], labels, log_scale=True, x_min=10**-8, x_max=10**6,\n",
    "                   plot_title=\"\", x_title=\"error\", normalize = False,\n",
    "                   bw_adjust=1, saveQ=True)\n",
    "    labels = [\"GC\",\"AT\"]\n",
    "    plot_relative_kdes([np.array(err_gc_data),np.array(err_at_data)], labels, log_scale=True, x_min=10**-8, x_max=10**6,\n",
    "                   plot_title=\"\", x_title=\"error\", normalize = False,\n",
    "                   bw_adjust=1, saveQ=True)\n",
    "    labels = [\"RFS\",\"CFS\",\"Centromeres\", \"Telomeres\"]\n",
    "    plot_relative_kdes([np.array(err_rfs_data),np.array(err_cfs_data),\n",
    "                    np.array(err_centromeres_data),np.array(err_telomeres_data)], labels, log_scale=True,\n",
    "                   x_min=10**-8, x_max=10**6,\n",
    "                   plot_title=\"\", x_title=\"error\", normalize = False,\n",
    "                   bw_adjust=1, saveQ=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd7e58-65c0-4397-920a-aa6a376277b6",
   "metadata": {},
   "source": [
    "#### Tests ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3926a62-d51d-47b8-9f0f-220e94a52f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
